{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ALVCxIwXo_UbDxN-O3galNGBSB_hOHcU",
      "authorship_tag": "ABX9TyNR40cwdLRWMpMZZrA3uiRI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prathamesh-kadam/GNN-Model/blob/main/Accessing_the_data_from_website.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import requests # Import the requests library\n",
        "\n",
        "# Define the URL for the file\n",
        "url = 'https://lweb.cfa.harvard.edu/supernova/CfA3/cfa3lightcurves.standardsystem.txt'\n",
        "filename = 'cfa3lightcurves.standardsystem.txt'\n",
        "\n",
        "# Download the file if it doesn't exist\n",
        "try:\n",
        "    with open(filename, 'r') as f:\n",
        "        pass # File exists, do nothing\n",
        "except FileNotFoundError:\n",
        "    print(f'Downloading {filename}...')\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "    print(f'Successfully downloaded {filename}.')\n",
        "\n",
        "# Read the downloaded file\n",
        "df_raw = pd.read_csv(filename,\n",
        "                     sep=r'\\s+', comment='#', header=None,\n",
        "                     names=['col1', 'col2', 'col3', 'col4'])\n",
        "\n",
        "# Filter out non-data rows and parse properly\n",
        "data = []\n",
        "current_sn = None\n",
        "filter_map = {1: 'U', 2: 'B', 3: 'V', 4: 'R', 5: 'I', 13: \"r'\", 14: \"i'\"}\n",
        "\n",
        "for index, row in df_raw.iterrows():\n",
        "    # Check if this is an SN name (string starting with 'sn')\n",
        "    if pd.isna(row['col1']) == False and str(row['col1']).startswith('sn'):\n",
        "        current_sn = str(row['col1'])\n",
        "        continue\n",
        "\n",
        "    # Check if this is a data row (filter code as first column)\n",
        "    if (pd.notna(row['col1']) and str(row['col1']).isdigit() and\n",
        "        int(row['col1']) in filter_map):\n",
        "\n",
        "        filt = int(row['col1'])\n",
        "        mjd = float(row['col2'])\n",
        "        stdmag = float(row['col3'])\n",
        "        dmag = float(row['col4'])\n",
        "\n",
        "        data.append({\n",
        "            'SN': current_sn,\n",
        "            'MJD': round(mjd, 5),  # Round for cleaner display\n",
        "            'Filter': filter_map[filt],\n",
        "            'STDMAG': stdmag,\n",
        "            'dMAG': dmag\n",
        "        })\n",
        "\n",
        "# Create clean DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Sort by SN, then MJD, then Filter for proper grouping\n",
        "df = df.sort_values(['SN', 'MJD', 'Filter']).reset_index(drop=True)\n",
        "\n",
        "# Save to Excel and CSV\n",
        "df.to_excel('cfa3_lightcurves.xlsx', index=False)\n",
        "df.to_csv('cfa3_lightcurves.csv', index=False)\n",
        "\n",
        "# Display summary\n",
        "print(f\"‚úÖ Success! Processed {len(df)} observations from {df['SN'].nunique()} supernovae\")\n",
        "print(\"\\nFirst 10 rows:\")\n",
        "print(df.head(10))\n",
        "print(\"\\nColumn structure:\")\n",
        "print(df.dtypes)\n",
        "print(\"\\nUnique SNe:\", sorted(df['SN'].unique())[:10], \"...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PwOsKxT6GRe",
        "outputId": "8f5c7284-2083-44eb-ffac-39c028279ac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading cfa3lightcurves.standardsystem.txt...\n",
            "Successfully downloaded cfa3lightcurves.standardsystem.txt.\n",
            "‚úÖ Success! Processed 11499 observations from 185 supernovae\n",
            "\n",
            "First 10 rows:\n",
            "      SN          MJD Filter  STDMAG   dMAG\n",
            "0  sn01C  51933.28865      U  17.043  0.035\n",
            "1  sn01C  51933.29189      B  16.503  0.015\n",
            "2  sn01C  51933.29438      V  15.442  0.014\n",
            "3  sn01C  51933.29616      R  15.170  0.019\n",
            "4  sn01C  51933.29758      I  15.181  0.022\n",
            "5  sn01C  51957.12972      U  18.000  0.039\n",
            "6  sn01C  51957.13304      B  17.639  0.027\n",
            "7  sn01C  51957.13560      V  16.557  0.022\n",
            "8  sn01C  51957.13747      R  16.177  0.028\n",
            "9  sn01C  51963.19172      U  18.111  0.069\n",
            "\n",
            "Column structure:\n",
            "SN         object\n",
            "MJD       float64\n",
            "Filter     object\n",
            "STDMAG    float64\n",
            "dMAG      float64\n",
            "dtype: object\n",
            "\n",
            "Unique SNe: ['sn01C', 'sn01G', 'sn01N', 'sn01V', 'sn01ah', 'sn01ay', 'sn01az', 'sn01bf', 'sn01cp', 'sn01da'] ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "0a78ec07",
        "outputId": "cb0db396-80d9-4624-f0c2-a099f1a45e7c"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('cfa3_lightcurves.xlsx')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_36bec6ef-6dbb-4526-ba14-ba2a86860bab\", \"cfa3_lightcurves.xlsx\", 345089)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de331f23",
        "outputId": "a26ff18a-70a0-4fb2-ab84-d2adc089aa83"
      },
      "source": [
        "print(f\"Number of unique supernovae: {df['SN'].nunique()}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique supernovae: 185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below code is to determine the apparent magnitude from the standard magnitude abotained for our 40 shortlisted supernovae matching it with 185 supernovae\n"
      ],
      "metadata": {
        "id": "zHrSur-IZ5oM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbfa2b9e",
        "outputId": "bc4f305f-1737-432b-e5b5-7e930b43ed4c"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import UnivariateSpline\n",
        "from astropy.stats import sigma_clipped_stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# File paths\n",
        "shortlisted_path = '/content/drive/MyDrive/apparent magnitude data/updated 40s_dataset.xlsx'  # Your 40 SNe [file:42]\n",
        "cfa_path = '/content/drive/MyDrive/apparent magnitude data/cfa3_lightcurves (1).xlsx'          # CFA3 lightcurves [file:41]\n",
        "output_path = '/content/drive/MyDrive/apparent magnitude data/updated_40s_with_peak_magnitudes.xlsx' # Changed output filename\n",
        "\n",
        "\n",
        "print(\"üîÑ Loading datasets...\")\n",
        "short_df = pd.read_excel(shortlisted_path, sheet_name='Sheet1')\n",
        "cfa_df = pd.read_excel(cfa_path, sheet_name='Sheet1')\n",
        "\n",
        "print(f\"‚úÖ Shortlisted: {len(short_df)} SNe\")\n",
        "print(f\"‚úÖ CFA3: {len(cfa_df)} data points\")\n",
        "print(\"CFA3 columns:\", cfa_df.columns.tolist())\n",
        "\n",
        "sn_names = short_df.iloc[:, 0].astype(str).str.strip().tolist()\n",
        "print(f\"First 5 shortlisted SNe: {sn_names[:5]}\")\n",
        "\n",
        "def extract_peak_magnitude(jd, mag, mag_err, n_iter=10000):\n",
        "    \"\"\"YOUR EXACT ORIGINAL CODE - unchanged\"\"\"\n",
        "    if len(jd) < 5:\n",
        "        return np.nan, np.nan\n",
        "\n",
        "    try:\n",
        "        # --- Fit initial spline ---\n",
        "        spline = UnivariateSpline(jd, mag, k=4, s=0.1)\n",
        "        fine_jd = np.linspace(jd.min(), jd.max(), 1000)\n",
        "        fine_mag = spline(fine_jd)\n",
        "\n",
        "        # --- Monte Carlo Simulation ---\n",
        "        mag_max_sim = []\n",
        "        for i in range(n_iter):\n",
        "            mag_sim = mag + np.random.normal(0, mag_err)\n",
        "            spline_sim = UnivariateSpline(jd, mag_sim, k=4, s=0.1)\n",
        "            fine_mag_sim = spline_sim(fine_jd)\n",
        "            mag_max_sim.append(np.min(fine_mag_sim))\n",
        "\n",
        "        # --- Sigma-Clipped Stats ---\n",
        "        mag_max_mean, _, mag_max_std = sigma_clipped_stats(np.array(mag_max_sim))\n",
        "        return mag_max_mean, mag_max_std\n",
        "\n",
        "    except:\n",
        "        return np.nan, np.nan\n",
        "\n",
        "# =============================================================================\n",
        "# PERFECT SN NAME MATCHING - Handles ALL CFA3 formats\n",
        "# =============================================================================\n",
        "def match_sn_names(short_name, cfa_names):\n",
        "    \"\"\"Matches: 1986G‚ÜíSN1986G/SN86G, 2001cp‚ÜíSN2001cp/SN01cp\"\"\"\n",
        "    short_name = short_name.strip().upper()\n",
        "\n",
        "    # Extract year components\n",
        "    if len(short_name) >= 5 and short_name[:4].isdigit():\n",
        "        year_full = short_name[:4]  # 1986, 2001\n",
        "        year_short = year_full[2:]  # 86, 01\n",
        "        sn_id = short_name[4:]      # G, cp\n",
        "    else:\n",
        "        year_full, year_short, sn_id = short_name, short_name, ''\n",
        "\n",
        "    candidates = []\n",
        "\n",
        "    for cfa_name in cfa_names:\n",
        "        cfa_clean = str(cfa_name).strip().upper()\n",
        "\n",
        "        # Pattern 1: Exact match\n",
        "        if short_name == cfa_clean:\n",
        "            candidates.append(cfa_clean)\n",
        "\n",
        "        # Pattern 2: SN + FULL YEAR (SN1986G, SN2001cp)\n",
        "        if f'SN{year_full}{sn_id}' in cfa_clean:\n",
        "            candidates.append(cfa_clean)\n",
        "\n",
        "        # Pattern 3: SN + SHORT YEAR (SN86G, SN01cp) - CRITICAL!\n",
        "        if f'SN{year_short}{sn_id}' in cfa_clean:\n",
        "            candidates.append(cfa_clean)\n",
        "\n",
        "    return candidates[0] if candidates else None\n",
        "\n",
        "print(\"\\nüöÄ Extracting peak magnitudes for ALL FILTERS...\")\n",
        "results_df = short_df.copy()\n",
        "\n",
        "# CFA3 filter-specific columns\n",
        "filter_columns = {\n",
        "    'U': {'mag': 'STDMAG_U', 'err': 'dMAG_U'},\n",
        "    'B': {'mag': 'STDMAG_B', 'err': 'dMAG_B'},\n",
        "    'V': {'mag': 'STDMAG_V', 'err': 'dMAG_V'},\n",
        "    'R': {'mag': 'STDMAG_R', 'err': 'dMAG_R'},\n",
        "    'I': {'mag': 'STDMAG_I', 'err': 'dMAG_I'}\n",
        "}\n",
        "\n",
        "# Add result columns for each filter\n",
        "for f in filter_columns.keys():\n",
        "    results_df[f'{f}_m_max'] = np.nan\n",
        "    results_df[f'{f}_m_max_err'] = np.nan\n",
        "\n",
        "# =============================================================================\n",
        "# MAIN PROCESSING LOOP\n",
        "# =============================================================================\n",
        "successful_matches = 0\n",
        "for idx, short_sn in enumerate(sn_names):\n",
        "    print(f\"\\n[{idx+1}/{len(sn_names)}] Processing: {short_sn}\")\n",
        "\n",
        "    # Find CFA3 match\n",
        "    cfa_sn_name = match_sn_names(short_sn, cfa_df['SN'].unique())\n",
        "\n",
        "    if cfa_sn_name is None:\n",
        "        print(f\"  ‚ùå No CFA3 match\")\n",
        "        continue\n",
        "\n",
        "    print(f\"  ‚úÖ MATCHED: {short_sn} ‚Üí {cfa_sn_name}\")\n",
        "    successful_matches += 1\n",
        "\n",
        "    # Get CFA3 data for this SN\n",
        "    sn_mask = cfa_df['SN'].astype(str).str.strip().str.upper() == cfa_sn_name\n",
        "    sn_data = cfa_df[sn_mask]\n",
        "\n",
        "    print(f\"  üìä {len(sn_data)} data points\")\n",
        "\n",
        "    # Process each filter\n",
        "    for f, cols in filter_columns.items():\n",
        "        # Filter by this specific filter\n",
        "        f_mask = (sn_data['Filter'] == f) if 'Filter' in sn_data.columns else True\n",
        "        f_data = sn_data[f_mask].copy()\n",
        "\n",
        "        if len(f_data) < 5:\n",
        "            continue\n",
        "\n",
        "        # Get JD, magnitude, error columns\n",
        "        jd = f_data['MJD'].values  # CFA3 uses MJD\n",
        "\n",
        "        # Try filter-specific columns first, fallback to generic\n",
        "        mag_col = cols['mag'] if cols['mag'] in f_data.columns else 'STDMAG'\n",
        "        err_col = cols['err'] if cols['err'] in f_data.columns else 'dMAG'\n",
        "\n",
        "        if mag_col not in f_data.columns or err_col not in f_data.columns:\n",
        "            continue\n",
        "\n",
        "        mag = f_data[mag_col].dropna().values\n",
        "        mag_err = f_data[err_col].fillna(0.05).dropna().values  # Default 0.05\n",
        "\n",
        "        # Align arrays (remove NaNs)\n",
        "        valid_idx = ~(np.isnan(jd) | np.isnan(mag) | np.isnan(mag_err))\n",
        "        jd, mag, mag_err = jd[valid_idx], mag[valid_idx], mag_err[valid_idx]\n",
        "\n",
        "        if len(jd) < 5:\n",
        "            continue\n",
        "\n",
        "        # Sort chronologically\n",
        "        sort_idx = np.argsort(jd)\n",
        "        jd, mag, mag_err = jd[sort_idx], mag[sort_idx], mag_err[sort_idx]\n",
        "\n",
        "        # YOUR EXACT PEAK FINDING ALGORITHM\n",
        "        m_max, m_err = extract_peak_magnitude(jd, mag, mag_err)\n",
        "\n",
        "        # Store in original row\n",
        "        row_idx = short_df[short_df.iloc[:, 0].astype(str) == short_sn].index[0]\n",
        "        results_df.at[row_idx, f'{f}_m_max'] = m_max\n",
        "        results_df.at[row_idx, f'{f}_m_max_err'] = m_err\n",
        "\n",
        "        if not np.isnan(m_max):\n",
        "            print(f\"  ‚úÖ {f}: m_max = {m_max:.3f} ¬± {m_err:.3f}\")\n",
        "\n",
        "print(f\"\\nüéâ PROCESSING COMPLETE!\")\n",
        "print(f\"‚úÖ Successfully matched {successful_matches}/{len(sn_names)} SNe\")\n",
        "results_df.to_excel(output_path, index=False)\n",
        "print(f\"‚úÖ SAVED: {output_path}\")\n",
        "\n",
        "# =============================================================================\n",
        "# SUMMARY TABLE\n",
        "# =============================================================================\n",
        "print(\"\\nüìä PEAK MAGNITUDE SUMMARY (first 10 SNe):\")\n",
        "summary_cols = [short_df.columns[0]] + [f'{f}_m_max' for f in filter_columns.keys()]\n",
        "print(results_df[summary_cols].round(3).head(10))\n",
        "\n",
        "print(f\"\\n‚úÖ **NEW COLUMNS ADDED**:\")\n",
        "print(f\"   U_m_max, U_m_max_err\")\n",
        "print(f\"   B_m_max, B_m_max_err\")\n",
        "print(f\"   V_m_max, V_m_max_err\")\n",
        "print(f\"   R_m_max, R_m_max_err\")\n",
        "print(f\"   I_m_max, I_m_max_err\")\n",
        "print(f\"\\n‚úÖ Ready for GNN/Phillips relation analysis!\")\n",
        "\n",
        "print(\"\\nFirst 10 rows of the updated DataFrame:\")\n",
        "print(results_df.head(10))\n",
        "print(\"\\nColumn names and data types of the updated DataFrame:\")\n",
        "print(results_df.info())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Loading datasets...\n",
            "‚úÖ Shortlisted: 41 SNe\n",
            "‚úÖ CFA3: 11499 data points\n",
            "CFA3 columns: ['SN', 'MJD', 'Filter', 'STDMAG', 'dMAG']\n",
            "First 5 shortlisted SNe: ['1986G', '1994D', '1997dt', '1998aq', '1998bu']\n",
            "\n",
            "üöÄ Extracting peak magnitudes for ALL FILTERS...\n",
            "\n",
            "[1/41] Processing: 1986G\n",
            "  ‚ùå No CFA3 match\n",
            "\n",
            "[2/41] Processing: 1994D\n",
            "  ‚ùå No CFA3 match\n",
            "\n",
            "[3/41] Processing: 1997dt\n",
            "  ‚ùå No CFA3 match\n",
            "\n",
            "[4/41] Processing: 1998aq\n",
            "  ‚ùå No CFA3 match\n",
            "\n",
            "[5/41] Processing: 1998bu\n",
            "  ‚ùå No CFA3 match\n",
            "\n",
            "[6/41] Processing: 1998dh\n",
            "  ‚ùå No CFA3 match\n",
            "\n",
            "[7/41] Processing: 1999cl\n",
            "  ‚ùå No CFA3 match\n",
            "\n",
            "[8/41] Processing: 1999ee\n",
            "  ‚ùå No CFA3 match\n",
            "\n",
            "[9/41] Processing: 2001cp\n",
            "  ‚úÖ MATCHED: 2001cp ‚Üí SN01CP\n",
            "  üìä 10 data points\n",
            "\n",
            "[10/41] Processing: 2002bo\n",
            "  ‚úÖ MATCHED: 2002bo ‚Üí SN02BO\n",
            "  üìä 86 data points\n",
            "  ‚úÖ U: m_max = 13.973 ¬± 0.056\n",
            "  ‚úÖ B: m_max = 14.045 ¬± 0.018\n",
            "  ‚úÖ V: m_max = 13.634 ¬± 0.013\n",
            "  ‚úÖ R: m_max = 13.499 ¬± 0.013\n",
            "  ‚úÖ I: m_max = 13.611 ¬± 0.011\n",
            "\n",
            "[11/41] Processing: 2002cr\n",
            "  ‚úÖ MATCHED: 2002cr ‚Üí SN02CR\n",
            "  üìä 44 data points\n",
            "  ‚úÖ U: m_max = 13.877 ¬± 0.122\n",
            "  ‚úÖ B: m_max = 14.263 ¬± 0.012\n",
            "  ‚úÖ V: m_max = 14.290 ¬± 0.010\n",
            "  ‚úÖ R: m_max = 14.256 ¬± 0.009\n",
            "  ‚úÖ I: m_max = 14.391 ¬± 0.012\n",
            "\n",
            "[12/41] Processing: 2002de\n",
            "  ‚úÖ MATCHED: 2002de ‚Üí SN02DE\n",
            "  üìä 29 data points\n",
            "  ‚úÖ U: m_max = 16.524 ¬± 0.050\n",
            "  ‚úÖ B: m_max = 16.735 ¬± 0.023\n",
            "  ‚úÖ V: m_max = 16.570 ¬± 0.010\n",
            "  ‚úÖ R: m_max = 16.437 ¬± 0.013\n",
            "  ‚úÖ I: m_max = 16.690 ¬± 0.022\n",
            "\n",
            "[13/41] Processing: 2002er\n",
            "  ‚ùå No CFA3 match\n",
            "\n",
            "[14/41] Processing: 2002he\n",
            "  ‚úÖ MATCHED: 2002he ‚Üí SN02HE\n",
            "  üìä 51 data points\n",
            "  ‚úÖ B: m_max = 16.434 ¬± 0.224\n",
            "  ‚úÖ V: m_max = 16.523 ¬± 0.037\n",
            "  ‚úÖ R: m_max = 16.533 ¬± 0.041\n",
            "  ‚úÖ I: m_max = 16.708 ¬± 0.031\n",
            "\n",
            "[15/41] Processing: 2003U\n",
            "  ‚úÖ MATCHED: 2003U ‚Üí SN03U\n",
            "  üìä 41 data points\n",
            "  ‚úÖ U: m_max = 15.631 ¬± 0.517\n",
            "  ‚úÖ B: m_max = 16.837 ¬± 0.087\n",
            "  ‚úÖ V: m_max = 16.588 ¬± 0.044\n",
            "  ‚úÖ R: m_max = 16.545 ¬± 0.063\n",
            "  ‚úÖ I: m_max = -355.012 ¬± 7537.048\n",
            "\n",
            "[16/41] Processing: 2003cg\n",
            "  ‚úÖ MATCHED: 2003cg ‚Üí SN03CG\n",
            "  üìä 55 data points\n",
            "  ‚úÖ U: m_max = 16.568 ¬± 0.032\n",
            "  ‚úÖ B: m_max = 15.912 ¬± 0.025\n",
            "  ‚úÖ V: m_max = 14.724 ¬± 0.007\n",
            "  ‚úÖ R: m_max = 14.200 ¬± 0.014\n",
            "  ‚úÖ I: m_max = 13.801 ¬± 0.013\n",
            "\n",
            "[17/41] Processing: 2003du\n",
            "  ‚úÖ MATCHED: 2003du ‚Üí SN03DU\n",
            "  üìä 109 data points\n",
            "  ‚úÖ U: m_max = 13.154 ¬± 0.022\n",
            "  ‚úÖ B: m_max = 13.435 ¬± 0.015\n",
            "  ‚úÖ V: m_max = 13.580 ¬± 0.009\n",
            "  ‚úÖ R: m_max = 13.613 ¬± 0.007\n",
            "  ‚úÖ I: m_max = 13.932 ¬± 0.012\n",
            "\n",
            "[18/41] Processing: 2004as\n",
            "  ‚úÖ MATCHED: 2004as ‚Üí SN04AS\n",
            "  üìä 51 data points\n",
            "  ‚úÖ B: m_max = 17.051 ¬± 0.021\n",
            "  ‚úÖ V: m_max = 16.950 ¬± 0.012\n",
            "  ‚úÖ R: m_max = 16.871 ¬± 0.013\n",
            "  ‚úÖ I: m_max = 17.128 ¬± 0.027\n",
            "\n",
            "[19/41] Processing: 2004at\n",
            "  ‚ùå No CFA3 match\n",
            "\n",
            "[20/41] Processing: 2004dt\n",
            "  ‚ùå No CFA3 match\n",
            "\n",
            "[21/41] Processing: 2004ef\n",
            "  ‚úÖ MATCHED: 2004ef ‚Üí SN04EF\n",
            "  üìä 32 data points\n",
            "  ‚úÖ B: m_max = 17.039 ¬± 0.037\n",
            "  ‚úÖ V: m_max = 16.962 ¬± 0.020\n",
            "\n",
            "[22/41] Processing: 2004fu\n",
            "  ‚úÖ MATCHED: 2004fu ‚Üí SN04FU\n",
            "  üìä 20 data points\n",
            "  ‚úÖ B: m_max = -41.589 ¬± 18.077\n",
            "  ‚úÖ V: m_max = 15.562 ¬± 0.012\n",
            "\n",
            "[23/41] Processing: 2005cf\n",
            "  ‚úÖ MATCHED: 2005cf ‚Üí SN05CF\n",
            "  üìä 110 data points\n",
            "  ‚úÖ U: m_max = 13.305 ¬± 0.004\n",
            "  ‚úÖ B: m_max = 13.608 ¬± 0.006\n",
            "  ‚úÖ V: m_max = 13.560 ¬± 0.006\n",
            "\n",
            "[24/41] Processing: 2005cg\n",
            "  ‚ùå No CFA3 match\n",
            "\n",
            "[25/41] Processing: 2005el\n",
            "  ‚úÖ MATCHED: 2005el ‚Üí SN05EL\n",
            "  üìä 250 data points\n",
            "  ‚úÖ U: m_max = -75925349828670.891 ¬± 7205647092633381.000\n",
            "  ‚úÖ B: m_max = 15.287 ¬± 0.016\n",
            "  ‚úÖ V: m_max = 15.286 ¬± 0.024\n",
            "\n",
            "[26/41] Processing: 2006S\n",
            "  ‚úÖ MATCHED: 2006S ‚Üí SN06S\n",
            "  üìä 143 data points\n",
            "  ‚úÖ U: m_max = -36527496079.789 ¬± 927604034477.731\n",
            "  ‚úÖ B: m_max = 16.893 ¬± 0.028\n",
            "  ‚úÖ V: m_max = 16.780 ¬± 0.013\n",
            "\n",
            "[27/41] Processing: 2006X\n",
            "  ‚úÖ MATCHED: 2006X ‚Üí SN06X\n",
            "  üìä 224 data points\n",
            "  ‚úÖ U: m_max = 13.373 ¬± 14.274\n",
            "  ‚úÖ B: m_max = 15.419 ¬± 0.019\n",
            "  ‚úÖ V: m_max = 14.111 ¬± 0.010\n",
            "\n",
            "[28/41] Processing: 2006ax\n",
            "  ‚úÖ MATCHED: 2006ax ‚Üí SN06AX\n",
            "  üìä 130 data points\n",
            "  ‚úÖ U: m_max = -508405440.540 ¬± 2600617458.868\n",
            "  ‚úÖ B: m_max = 15.239 ¬± 0.007\n",
            "  ‚úÖ V: m_max = 15.282 ¬± 0.007\n",
            "\n",
            "[29/41] Processing: 2006gr\n",
            "  ‚úÖ MATCHED: 2006gr ‚Üí SN06GR\n",
            "  üìä 129 data points\n",
            "  ‚úÖ U: m_max = 17.061 ¬± 0.662\n",
            "  ‚úÖ B: m_max = 17.284 ¬± 0.023\n",
            "  ‚úÖ V: m_max = 17.113 ¬± 0.012\n",
            "\n",
            "[30/41] Processing: 2007F\n",
            "  ‚úÖ MATCHED: 2007F ‚Üí SN07F\n",
            "  üìä 127 data points\n",
            "  ‚úÖ B: m_max = 15.932 ¬± 0.013\n",
            "  ‚úÖ V: m_max = 16.014 ¬± 0.015\n",
            "\n",
            "[31/41] Processing: 2007af\n",
            "  ‚úÖ MATCHED: 2007af ‚Üí SN07AF\n",
            "  üìä 225 data points\n",
            "  ‚úÖ B: m_max = 13.291 ¬± 0.010\n",
            "  ‚úÖ V: m_max = 13.206 ¬± 0.005\n",
            "\n",
            "[32/41] Processing: 2007bd\n",
            "  ‚úÖ MATCHED: 2007bd ‚Üí SN07BD\n",
            "  üìä 46 data points\n",
            "  ‚úÖ B: m_max = 16.671 ¬± 0.008\n",
            "  ‚úÖ V: m_max = 16.649 ¬± 0.006\n",
            "\n",
            "[33/41] Processing: 2007co\n",
            "  ‚úÖ MATCHED: 2007co ‚Üí SN07CO\n",
            "  üìä 122 data points\n",
            "  ‚úÖ U: m_max = 17.166 ¬± 0.029\n",
            "  ‚úÖ B: m_max = 16.896 ¬± 0.011\n",
            "  ‚úÖ V: m_max = 16.699 ¬± 0.006\n",
            "\n",
            "[34/41] Processing: 2007le\n",
            "  ‚ùå No CFA3 match\n",
            "\n",
            "[35/41] Processing: 2008Q\n",
            "  ‚ùå No CFA3 match\n",
            "\n",
            "[36/41] Processing: 2008ar\n",
            "  ‚ùå No CFA3 match\n",
            "\n",
            "[37/41] Processing: 2008bf\n",
            "  ‚úÖ MATCHED: 2008bf ‚Üí SN08BF\n",
            "  üìä 81 data points\n",
            "  ‚úÖ U: m_max = 15.226 ¬± 1.262\n",
            "  ‚úÖ B: m_max = 15.844 ¬± 0.013\n",
            "  ‚úÖ V: m_max = 15.780 ¬± 0.010\n",
            "\n",
            "[38/41] Processing: 2011fe\n",
            "  ‚ùå No CFA3 match\n",
            "\n",
            "[39/41] Processing: 2014J\n",
            "  ‚ùå No CFA3 match\n",
            "\n",
            "[40/41] Processing: 2016coj\n",
            "  ‚ùå No CFA3 match\n",
            "\n",
            "[41/41] Processing: 2017erp\n",
            "  ‚ùå No CFA3 match\n",
            "\n",
            "üéâ PROCESSING COMPLETE!\n",
            "‚úÖ Successfully matched 22/41 SNe\n",
            "‚úÖ SAVED: /content/drive/MyDrive/apparent magnitude data/updated_40s_with_peak_magnitudes.xlsx\n",
            "\n",
            "üìä PEAK MAGNITUDE SUMMARY (first 10 SNe):\n",
            "       SN  U_m_max  B_m_max  V_m_max  R_m_max  I_m_max\n",
            "0   1986G      NaN      NaN      NaN      NaN      NaN\n",
            "1   1994D      NaN      NaN      NaN      NaN      NaN\n",
            "2  1997dt      NaN      NaN      NaN      NaN      NaN\n",
            "3  1998aq      NaN      NaN      NaN      NaN      NaN\n",
            "4  1998bu      NaN      NaN      NaN      NaN      NaN\n",
            "5  1998dh      NaN      NaN      NaN      NaN      NaN\n",
            "6  1999cl      NaN      NaN      NaN      NaN      NaN\n",
            "7  1999ee      NaN      NaN      NaN      NaN      NaN\n",
            "8  2001cp      NaN      NaN      NaN      NaN      NaN\n",
            "9  2002bo   13.973   14.045   13.634   13.499   13.611\n",
            "\n",
            "‚úÖ **NEW COLUMNS ADDED**:\n",
            "   U_m_max, U_m_max_err\n",
            "   B_m_max, B_m_max_err\n",
            "   V_m_max, V_m_max_err\n",
            "   R_m_max, R_m_max_err\n",
            "   I_m_max, I_m_max_err\n",
            "\n",
            "‚úÖ Ready for GNN/Phillips relation analysis!\n",
            "\n",
            "First 10 rows of the updated DataFrame:\n",
            "       SN  Phase_days Subtype  Delta_m15_B_mag  V4130_Si_km_s  W4130_Si_A  \\\n",
            "0   1986G         0.0      NV            1.650            NaN         NaN   \n",
            "1   1994D         1.5      NV            1.370         9962.0        23.0   \n",
            "2  1997dt         0.2      NV            1.040        10865.0        19.0   \n",
            "3  1998aq        -0.2      NV            1.110         9684.0         9.0   \n",
            "4  1998bu        -1.5      NV            1.030            NaN         NaN   \n",
            "5  1998dh        -0.5      HV            1.227        10115.0        24.0   \n",
            "6  1999cl         0.7      HV            1.144         9711.0        29.0   \n",
            "7  1999ee        -0.4      NV            0.960            NaN         NaN   \n",
            "8  2001cp         0.9      NV            0.915         9834.0         8.0   \n",
            "9  2002bo        -1.5      HV            1.080        10758.0        24.0   \n",
            "\n",
            "   V5972_Si_km_s  W5972_Si_A  V6355_Si_km_s  W6355_Si_A  ...    U_m_max  \\\n",
            "0           8759          62           9900         134  ...        NaN   \n",
            "1          10782          24          10888         104  ...        NaN   \n",
            "2          10668          11          10929          88  ...        NaN   \n",
            "3          10360          15          10424          82  ...        NaN   \n",
            "4           9768          18          10717          93  ...        NaN   \n",
            "5          11309          27          12000         128  ...        NaN   \n",
            "6          10243          30          12128         138  ...        NaN   \n",
            "7           9140          21          11140          89  ...        NaN   \n",
            "8          10547           7          10550          80  ...        NaN   \n",
            "9          11213          19          13213         153  ...  13.972966   \n",
            "\n",
            "   U_m_max_err   B_m_max  B_m_max_err    V_m_max V_m_max_err    R_m_max  \\\n",
            "0          NaN       NaN          NaN        NaN         NaN        NaN   \n",
            "1          NaN       NaN          NaN        NaN         NaN        NaN   \n",
            "2          NaN       NaN          NaN        NaN         NaN        NaN   \n",
            "3          NaN       NaN          NaN        NaN         NaN        NaN   \n",
            "4          NaN       NaN          NaN        NaN         NaN        NaN   \n",
            "5          NaN       NaN          NaN        NaN         NaN        NaN   \n",
            "6          NaN       NaN          NaN        NaN         NaN        NaN   \n",
            "7          NaN       NaN          NaN        NaN         NaN        NaN   \n",
            "8          NaN       NaN          NaN        NaN         NaN        NaN   \n",
            "9     0.055943  14.04522     0.018181  13.634432    0.013359  13.499266   \n",
            "\n",
            "   R_m_max_err    I_m_max  I_m_max_err  \n",
            "0          NaN        NaN          NaN  \n",
            "1          NaN        NaN          NaN  \n",
            "2          NaN        NaN          NaN  \n",
            "3          NaN        NaN          NaN  \n",
            "4          NaN        NaN          NaN  \n",
            "5          NaN        NaN          NaN  \n",
            "6          NaN        NaN          NaN  \n",
            "7          NaN        NaN          NaN  \n",
            "8          NaN        NaN          NaN  \n",
            "9     0.013176  13.611189     0.010927  \n",
            "\n",
            "[10 rows x 26 columns]\n",
            "\n",
            "Column names and data types of the updated DataFrame:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 41 entries, 0 to 40\n",
            "Data columns (total 26 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   SN               41 non-null     object \n",
            " 1   Phase_days       41 non-null     float64\n",
            " 2   Subtype          41 non-null     object \n",
            " 3   Delta_m15_B_mag  40 non-null     float64\n",
            " 4   V4130_Si_km_s    31 non-null     float64\n",
            " 5   W4130_Si_A       31 non-null     float64\n",
            " 6   V5972_Si_km_s    41 non-null     int64  \n",
            " 7   W5972_Si_A       41 non-null     int64  \n",
            " 8   V6355_Si_km_s    41 non-null     int64  \n",
            " 9   W6355_Si_A       41 non-null     int64  \n",
            " 10  V5454_S_km_s     41 non-null     int64  \n",
            " 11  W5454_S_A        41 non-null     int64  \n",
            " 12  V5620_S_km_s     41 non-null     int64  \n",
            " 13  W5620_S_A        41 non-null     int64  \n",
            " 14  Source           41 non-null     object \n",
            " 15  Reference        41 non-null     object \n",
            " 16  U_m_max          14 non-null     float64\n",
            " 17  U_m_max_err      14 non-null     float64\n",
            " 18  B_m_max          21 non-null     float64\n",
            " 19  B_m_max_err      21 non-null     float64\n",
            " 20  V_m_max          21 non-null     float64\n",
            " 21  V_m_max_err      21 non-null     float64\n",
            " 22  R_m_max          8 non-null      float64\n",
            " 23  R_m_max_err      8 non-null      float64\n",
            " 24  I_m_max          8 non-null      float64\n",
            " 25  I_m_max_err      8 non-null      float64\n",
            "dtypes: float64(14), int64(8), object(4)\n",
            "memory usage: 8.5+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below code is to extract the extinction value, distance modulus and modulus error from the .dat file obtained from the website: \"https://github.com/PantheonPlusSH0ES/DataRelease/blob/main/Pantheon%2B_Data/4_DISTANCES_AND_COVAR/Pantheon%2BSH0ES.dat\" and add it to the file containing the 185 supernovae..."
      ],
      "metadata": {
        "id": "rJX4_6V9ZnmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# File paths - UPDATE THESE PATHS FOR YOUR ENVIRONMENT\n",
        "# Since Pantheon-SH0ES.dat is attached as 'Pantheon-SH0ES.dat', use that directly\n",
        "pantheon_dat_path = \"/content/drive/MyDrive/apparent magnitude data/Pantheon+SH0ES.dat\"\n",
        "cfa3_path = \"/content/drive/MyDrive/apparent magnitude data/cfa3_lightcurves (1).xlsx\"  # Update if needed\n",
        "\n",
        "def convert_sn_name(sn_name):\n",
        "    \"\"\"Convert 'sn01C' ‚Üí '2001C' or handle variations\"\"\"\n",
        "    if pd.isna(sn_name) or sn_name == 'SN':\n",
        "        return None\n",
        "    sn_str = str(sn_name).strip().upper()\n",
        "    if sn_str.startswith('SN'):\n",
        "        year = sn_str[2:4]\n",
        "        letter = sn_str[4:]\n",
        "        return f\"20{year}{letter}\"\n",
        "    return sn_str\n",
        "\n",
        "# Load CfA3 data\n",
        "print(\"üîç Loading CfA3 file...\")\n",
        "cfa3_df = pd.read_excel(cfa3_path)\n",
        "cfa3_sns = cfa3_df['SN'].dropna().unique()\n",
        "print(f\"Found {len(cfa3_sns)} unique CfA3 SNe: {cfa3_sns[:5]}\")\n",
        "\n",
        "# Load Pantheon+SH0ES DAT file PROPERLY\n",
        "print(\"\\nüîç Loading Pantheon+SH0ES.dat...\")\n",
        "pantheon_raw = pd.read_csv(pantheon_dat_path, sep=r'\\s+', comment='#', header=None)\n",
        "\n",
        "# First row is HEADER - extract column names and indices\n",
        "header_row = pantheon_raw.iloc[0]\n",
        "data_rows = pantheon_raw.iloc[1:].reset_index(drop=True)\n",
        "\n",
        "# Find exact column indices using header names\n",
        "try:\n",
        "    cid_col = header_row[header_row.str.contains('CID', case=False, na=False)].index[0]\n",
        "    mu_col = header_row[header_row.str.contains('MU_SH0ES', case=False, na=False)].index[0]\n",
        "    mu_err_col = header_row[header_row.str.contains('MU_SH0ES_ERR_DIAG|MU_SH0ESERRDIAG', case=False, na=False)].index[0]\n",
        "    mwebv_col = header_row[header_row.str.contains('MWEBV', case=False, na=False)].index[0]\n",
        "\n",
        "    print(f\"‚úÖ Column indices found:\")\n",
        "    print(f\"   CID: {cid_col}, MU_SH0ES: {mu_col}, MU_ERR: {mu_err_col}, MWEBV: {mwebv_col}\")\n",
        "    print(f\"   Total columns: {len(header_row)}\")\n",
        "\n",
        "except:\n",
        "    print(\"‚ùå Could not find column headers - check file format\")\n",
        "    print(\"Header sample:\", header_row[:15].tolist())\n",
        "    exit()\n",
        "\n",
        "pantheon_sn_col = int(cid_col)\n",
        "pantheon_mu_col = int(mu_col)\n",
        "pantheon_mu_err_col = int(mu_err_col)\n",
        "pantheon_mwebv_col = int(mwebv_col)\n",
        "\n",
        "# Process matches\n",
        "matches = []\n",
        "print(f\"\\nüîç Searching for matches among {len(data_rows)} Pantheon rows...\")\n",
        "\n",
        "for cfa_sn in cfa3_sns:\n",
        "    pantheon_sn = convert_sn_name(cfa_sn)\n",
        "\n",
        "    # Search in SN name column (case-insensitive)\n",
        "    mask = data_rows.iloc[:, pantheon_sn_col].astype(str).str.contains(\n",
        "        pantheon_sn, case=False, na=False\n",
        "    )\n",
        "    found_rows = data_rows[mask]\n",
        "\n",
        "    if not found_rows.empty:\n",
        "        # Take FIRST matching row (as in original code)\n",
        "        row = found_rows.iloc[0]\n",
        "\n",
        "        # Extract values SAFELY\n",
        "        mu_sh0es = pd.to_numeric(row.iloc[pantheon_mu_col], errors='coerce')\n",
        "        mu_sh0es_err = pd.to_numeric(row.iloc[pantheon_mu_err_col], errors='coerce')\n",
        "        mwebv = pd.to_numeric(row.iloc[pantheon_mwebv_col], errors='coerce')\n",
        "\n",
        "        # Filter invalid values\n",
        "        if mu_sh0es == -999.0 or pd.isna(mu_sh0es) or mu_sh0es > 100:\n",
        "            mu_sh0es = np.nan\n",
        "        if pd.isna(mu_sh0es_err) or mu_sh0es_err <= 0:\n",
        "            mu_sh0es_err = np.nan\n",
        "        if pd.isna(mwebv) or mwebv == -999.0:\n",
        "            mwebv = np.nan\n",
        "\n",
        "        matches.append({\n",
        "            'cfa3_name': cfa_sn,\n",
        "            'pantheon_name': pantheon_sn,\n",
        "            'pantheon_row_idx': found_rows.index[0],  # Original row index\n",
        "            'MU_SH0ES': mu_sh0es,\n",
        "            'MU_SH0ES_ERR_DIAG': mu_sh0es_err,\n",
        "            'MWEBV': mwebv\n",
        "        })\n",
        "        print(f\"   ‚úÖ Match: {cfa_sn} ‚Üí {pantheon_sn} (MU={mu_sh0es:.3f})\")\n",
        "\n",
        "matches_df = pd.DataFrame(matches)\n",
        "print(f\"\\nüéâ Found {len(matches_df)} total matches!\")\n",
        "\n",
        "# Display match statistics\n",
        "print(\"\\nüìä Match Summary:\")\n",
        "print(matches_df[['cfa3_name', 'pantheon_name', 'MU_SH0ES', 'MU_SH0ES_ERR_DIAG', 'MWEBV']].head(10))\n",
        "\n",
        "# Merge with CfA3 data\n",
        "if len(matches_df) > 0:\n",
        "    # Create dictionaries for mapping\n",
        "    mu_dict = dict(zip(matches_df['cfa3_name'], matches_df['MU_SH0ES']))\n",
        "    mu_err_dict = dict(zip(matches_df['cfa3_name'], matches_df['MU_SH0ES_ERR_DIAG']))\n",
        "    mwebv_dict = dict(zip(matches_df['cfa3_name'], matches_df['MWEBV']))\n",
        "\n",
        "    # Add to CfA3 dataframe\n",
        "    cfa3_df['MU_SH0ES'] = cfa3_df['SN'].map(mu_dict)\n",
        "    cfa3_df['MU_SH0ES_ERR_DIAG'] = cfa3_df['SN'].map(mu_err_dict)\n",
        "    cfa3_df['MWEBV'] = cfa3_df['SN'].map(mwebv_dict)\n",
        "\n",
        "    # Verify\n",
        "    matched_mask = cfa3_df['MU_SH0ES'].notna()\n",
        "    print(f\"\\n‚úÖ Added values to {matched_mask.sum()} CfA3 rows ({matched_mask.sum()/len(cfa3_df)*100:.1f}% match rate)\")\n",
        "\n",
        "    print(\"\\nüìã Sample enhanced rows:\")\n",
        "    sample = cfa3_df[matched_mask][['SN', 'MU_SH0ES', 'MU_SH0ES_ERR_DIAG', 'MWEBV']].head()\n",
        "    print(sample)\n",
        "\n",
        "    # Save enhanced files\n",
        "    output_path = \"/content/drive/MyDrive/apparent magnitude data/cfa3_lightcurves_enhanced.xlsx\"\n",
        "    cfa3_df.to_excel(output_path, index=False)\n",
        "    print(f\"\\nüíæ Enhanced CfA3 saved: {output_path}\")\n",
        "\n",
        "    matches_path = \"/content/drive/MyDrive/apparent magnitude data/cfa3_pantheon_matches_detailed.csv\"\n",
        "    matches_df.to_csv(matches_path, index=False)\n",
        "    print(f\"üíæ Matches summary saved: {matches_path}\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå No matches found. Check SN name formats.\")\n",
        "    print(\"CfA3 sample names:\", cfa3_sns[:10])\n",
        "    print(\"Pantheon sample names:\", data_rows.iloc[:, pantheon_sn_col].unique()[:10])\n",
        "\n",
        "print(\"\\nüéØ Ready for absolute magnitude: M = m - MU_SH0ES - (3.1 * MWEBV)\")\n",
        "print(\"‚úÖ Fixed: Proper header parsing, dynamic column detection, safe numeric conversion!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMbuMSzcWjfa",
        "outputId": "28d624c9-41ad-4090-fc54-865d0054b802"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Loading CfA3 file...\n",
            "Found 185 unique CfA3 SNe: ['sn01C' 'sn01G' 'sn01N' 'sn01V' 'sn01ah']\n",
            "\n",
            "üîç Loading Pantheon+SH0ES.dat...\n",
            "‚úÖ Column indices found:\n",
            "   CID: 0, MU_SH0ES: 10, MU_ERR: 11, MWEBV: 33\n",
            "   Total columns: 47\n",
            "\n",
            "üîç Searching for matches among 1701 Pantheon rows...\n",
            "   ‚úÖ Match: sn01C ‚Üí 2001C (MU=33.878)\n",
            "   ‚úÖ Match: sn01V ‚Üí 2001V (MU=33.790)\n",
            "   ‚úÖ Match: sn01ah ‚Üí 2001AH (MU=36.980)\n",
            "   ‚úÖ Match: sn01az ‚Üí 2001AZ (MU=36.315)\n",
            "   ‚úÖ Match: sn01bf ‚Üí 2001BF (MU=33.993)\n",
            "   ‚úÖ Match: sn01cp ‚Üí 2001CP (MU=34.965)\n",
            "   ‚úÖ Match: sn01da ‚Üí 2001DA (MU=34.022)\n",
            "   ‚úÖ Match: sn01eh ‚Üí 2001EH (MU=36.007)\n",
            "   ‚úÖ Match: sn01en ‚Üí 2001EN (MU=33.999)\n",
            "   ‚úÖ Match: sn01ep ‚Üí 2001EP (MU=33.636)\n",
            "   ‚úÖ Match: sn01fe ‚Üí 2001FE (MU=33.892)\n",
            "   ‚úÖ Match: sn02G ‚Üí 2002G (MU=35.806)\n",
            "   ‚úÖ Match: sn02bf ‚Üí 2002BF (MU=34.944)\n",
            "   ‚úÖ Match: sn02cr ‚Üí 2002CR (MU=33.231)\n",
            "   ‚úÖ Match: sn02de ‚Üí 2002DE (MU=35.364)\n",
            "   ‚úÖ Match: sn02dj ‚Üí 2002DJ (MU=32.901)\n",
            "   ‚úÖ Match: sn02dp ‚Üí 2002DP (MU=33.381)\n",
            "   ‚úÖ Match: sn02eu ‚Üí 2002EU (MU=36.062)\n",
            "   ‚úÖ Match: sn02fk ‚Üí 2002FK (MU=32.442)\n",
            "   ‚úÖ Match: sn02ha ‚Üí 2002HA (MU=33.708)\n",
            "   ‚úÖ Match: sn02he ‚Üí 2002HE (MU=35.114)\n",
            "   ‚úÖ Match: sn02hu ‚Üí 2002HU (MU=35.964)\n",
            "   ‚úÖ Match: sn02jy ‚Üí 2002JY (MU=34.999)\n",
            "   ‚úÖ Match: sn02kf ‚Üí 2002KF (MU=34.685)\n",
            "   ‚úÖ Match: sn03D ‚Üí 2003D (MU=32.794)\n",
            "   ‚úÖ Match: sn03K ‚Üí 2003K (MU=32.642)\n",
            "   ‚úÖ Match: sn03U ‚Üí 2003U (MU=35.267)\n",
            "   ‚úÖ Match: sn03W ‚Üí 2003W (MU=34.674)\n",
            "   ‚úÖ Match: sn03ch ‚Üí 2003CH (MU=35.602)\n",
            "   ‚úÖ Match: sn03cq ‚Üí 2003CQ (MU=35.828)\n",
            "   ‚úÖ Match: sn03du ‚Üí 2003DU (MU=32.794)\n",
            "   ‚úÖ Match: sn03fa ‚Üí 2003FA (MU=36.017)\n",
            "   ‚úÖ Match: sn03ic ‚Üí 2003IC (MU=36.393)\n",
            "   ‚úÖ Match: sn03it ‚Üí 2003IT (MU=35.079)\n",
            "   ‚úÖ Match: sn03iv ‚Üí 2003IV (MU=35.912)\n",
            "   ‚úÖ Match: sn03kc ‚Üí 2003KC (MU=35.857)\n",
            "   ‚úÖ Match: sn03kf ‚Üí 2003KF (MU=32.642)\n",
            "   ‚úÖ Match: sn04L ‚Üí 2004L (MU=35.829)\n",
            "   ‚úÖ Match: sn04as ‚Üí 2004AS (MU=35.732)\n",
            "   ‚úÖ Match: sn04bg ‚Üí 2004BG (MU=34.773)\n",
            "   ‚úÖ Match: sn04ef ‚Üí 2004EF (MU=35.520)\n",
            "   ‚úÖ Match: sn05M ‚Üí 2005M (MU=35.293)\n",
            "   ‚úÖ Match: sn05am ‚Üí 2005AM (MU=32.374)\n",
            "   ‚úÖ Match: sn05cf ‚Üí 2005CF (MU=32.319)\n",
            "   ‚úÖ Match: sn05el ‚Üí 2005EL (MU=33.974)\n",
            "   ‚úÖ Match: sn05eq ‚Üí 2005EQ (MU=35.506)\n",
            "   ‚úÖ Match: sn05eu ‚Üí 2005EU (MU=35.801)\n",
            "   ‚úÖ Match: sn05hc ‚Üí 2005HC (MU=36.463)\n",
            "   ‚úÖ Match: sn05hj ‚Üí 2005HJ (MU=36.990)\n",
            "   ‚úÖ Match: sn05iq ‚Üí 2005IQ (MU=35.865)\n",
            "   ‚úÖ Match: sn05ir ‚Üí 2005IR (MU=37.566)\n",
            "   ‚úÖ Match: sn05kc ‚Üí 2005KC (MU=34.019)\n",
            "   ‚úÖ Match: sn05ki ‚Üí 2005KI (MU=34.571)\n",
            "   ‚úÖ Match: sn05lz ‚Üí 2005LZ (MU=36.325)\n",
            "   ‚úÖ Match: sn05mc ‚Üí 2005MC (MU=35.285)\n",
            "   ‚úÖ Match: sn05ms ‚Üí 2005MS (MU=35.308)\n",
            "   ‚úÖ Match: sn05na ‚Üí 2005NA (MU=35.113)\n",
            "   ‚úÖ Match: sn06B ‚Üí 2006B (MU=33.279)\n",
            "   ‚úÖ Match: sn06D ‚Üí 2006D (MU=31.186)\n",
            "   ‚úÖ Match: sn06H ‚Üí 2006H (MU=36.456)\n",
            "   ‚úÖ Match: sn06N ‚Üí 2006N (MU=33.908)\n",
            "   ‚úÖ Match: sn06S ‚Üí 2006S (MU=34.995)\n",
            "   ‚úÖ Match: sn06ac ‚Üí 2006AC (MU=34.987)\n",
            "   ‚úÖ Match: sn06al ‚Üí 2006AL (MU=37.421)\n",
            "   ‚úÖ Match: sn06ax ‚Üí 2006AX (MU=34.323)\n",
            "   ‚úÖ Match: sn06az ‚Üí 2006AZ (MU=35.490)\n",
            "   ‚úÖ Match: sn06bq ‚Üí 2006BQ (MU=34.869)\n",
            "   ‚úÖ Match: sn06bt ‚Üí 2006BT (MU=35.772)\n",
            "   ‚úÖ Match: sn06bw ‚Üí 2006BW (MU=35.623)\n",
            "   ‚úÖ Match: sn06cf ‚Üí 2006CF (MU=36.293)\n",
            "   ‚úÖ Match: sn06cp ‚Üí 2006CP (MU=34.771)\n",
            "   ‚úÖ Match: sn06cq ‚Üí 2006CQ (MU=36.583)\n",
            "   ‚úÖ Match: sn06cz ‚Üí 2006CZ (MU=35.914)\n",
            "   ‚úÖ Match: sn06ef ‚Üí 2006EF (MU=34.361)\n",
            "   ‚úÖ Match: sn06ej ‚Üí 2006EJ (MU=34.599)\n",
            "   ‚úÖ Match: sn06en ‚Üí 2006EN (MU=35.647)\n",
            "   ‚úÖ Match: sn06et ‚Üí 2006ET (MU=34.758)\n",
            "   ‚úÖ Match: sn06ev ‚Üí 2006EV (MU=35.674)\n",
            "   ‚úÖ Match: sn06gj ‚Üí 2006GJ (MU=35.726)\n",
            "   ‚úÖ Match: sn06gr ‚Üí 2006GR (MU=35.919)\n",
            "   ‚úÖ Match: sn06gt ‚Üí 2006GT (MU=36.511)\n",
            "   ‚úÖ Match: sn06kf ‚Üí 2006KF (MU=34.775)\n",
            "   ‚úÖ Match: sn06mo ‚Üí 2006MO (MU=36.069)\n",
            "   ‚úÖ Match: sn06oa ‚Üí 2006OA (MU=37.075)\n",
            "   ‚úÖ Match: sn06ob ‚Üí 2006OB (MU=36.982)\n",
            "   ‚úÖ Match: sn06on ‚Üí 2006ON (MU=37.454)\n",
            "   ‚úÖ Match: sn06os ‚Üí 2006OS (MU=35.799)\n",
            "   ‚úÖ Match: sn06ot ‚Üí 2006OT (MU=36.868)\n",
            "   ‚úÖ Match: sn06qo ‚Üí 2006QO (MU=35.478)\n",
            "   ‚úÖ Match: sn06sr ‚Üí 2006SR (MU=34.995)\n",
            "   ‚úÖ Match: sn06td ‚Üí 2006TD (MU=34.173)\n",
            "   ‚úÖ Match: sn06te ‚Üí 2006TE (MU=35.725)\n",
            "   ‚úÖ Match: sn07F ‚Üí 2007F (MU=34.341)\n",
            "   ‚úÖ Match: sn07H ‚Üí 2007H (MU=33.968)\n",
            "   ‚úÖ Match: sn07N ‚Üí 2007N (MU=36.214)\n",
            "   ‚úÖ Match: sn07O ‚Üí 2007O (MU=31.652)\n",
            "   ‚úÖ Match: sn07S ‚Üí 2007S (MU=31.680)\n",
            "   ‚úÖ Match: sn07ae ‚Üí 2007AE (MU=37.085)\n",
            "   ‚úÖ Match: sn07af ‚Üí 2007AF (MU=32.067)\n",
            "   ‚úÖ Match: sn07ai ‚Üí 2007AI (MU=35.856)\n",
            "   ‚úÖ Match: sn07au ‚Üí 2007AU (MU=34.687)\n",
            "   ‚úÖ Match: sn07ba ‚Üí 2007BA (MU=35.825)\n",
            "   ‚úÖ Match: sn07bc ‚Üí 2007BC (MU=34.756)\n",
            "   ‚úÖ Match: sn07bd ‚Üí 2007BD (MU=35.496)\n",
            "   ‚úÖ Match: sn07ca ‚Üí 2007CA (MU=34.337)\n",
            "   ‚úÖ Match: sn07ci ‚Üí 2007CI (MU=34.648)\n",
            "   ‚úÖ Match: sn07co ‚Üí 2007CO (MU=35.344)\n",
            "   ‚úÖ Match: sn07cq ‚Üí 2007CQ (MU=34.837)\n",
            "   ‚úÖ Match: sn07qe ‚Üí 2007QE (MU=35.041)\n",
            "   ‚úÖ Match: sn07sr ‚Üí 2007SR (MU=31.680)\n",
            "   ‚úÖ Match: sn08L ‚Üí 2008L (MU=34.336)\n",
            "   ‚úÖ Match: sn08bf ‚Üí 2008BF (MU=35.106)\n",
            "\n",
            "üéâ Found 112 total matches!\n",
            "\n",
            "üìä Match Summary:\n",
            "  cfa3_name pantheon_name  MU_SH0ES  MU_SH0ES_ERR_DIAG     MWEBV\n",
            "0     sn01C         2001C   33.8783           0.346381  0.078962\n",
            "1     sn01V         2001V   33.7902           0.290577  0.016837\n",
            "2    sn01ah        2001AH   36.9802           0.215566  0.011075\n",
            "3    sn01az        2001AZ   36.3153           0.150794  0.043583\n",
            "4    sn01bf        2001BF   33.9926           0.239289  0.084959\n",
            "5    sn01cp        2001CP   34.9654           0.216973  0.134690\n",
            "6    sn01da        2001DA   34.0220           0.308995  0.049898\n",
            "7    sn01eh        2001EH   36.0067           0.135213  0.054700\n",
            "8    sn01en        2001EN   33.9994           0.286320  0.046386\n",
            "9    sn01ep        2001EP   33.6365           0.287379  0.040717\n",
            "\n",
            "‚úÖ Added values to 7586 CfA3 rows (66.0% match rate)\n",
            "\n",
            "üìã Sample enhanced rows:\n",
            "      SN  MU_SH0ES  MU_SH0ES_ERR_DIAG     MWEBV\n",
            "0  sn01C   33.8783           0.346381  0.078962\n",
            "1  sn01C   33.8783           0.346381  0.078962\n",
            "2  sn01C   33.8783           0.346381  0.078962\n",
            "3  sn01C   33.8783           0.346381  0.078962\n",
            "4  sn01C   33.8783           0.346381  0.078962\n",
            "\n",
            "üíæ Enhanced CfA3 saved: /content/drive/MyDrive/apparent magnitude data/cfa3_lightcurves_enhanced.xlsx\n",
            "üíæ Matches summary saved: /content/drive/MyDrive/apparent magnitude data/cfa3_pantheon_matches_detailed.csv\n",
            "\n",
            "üéØ Ready for absolute magnitude: M = m - MU_SH0ES - (3.1 * MWEBV)\n",
            "‚úÖ Fixed: Proper header parsing, dynamic column detection, safe numeric conversion!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install extinction\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8alYSeYsa5BL",
        "outputId": "aebc5b48-12d2-4b5f-cfc5-c23bc8f26984"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting extinction\n",
            "  Downloading extinction-0.4.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (795 bytes)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from extinction) (2.0.2)\n",
            "Downloading extinction-0.4.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (627 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m627.8/627.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: extinction\n",
            "Successfully installed extinction-0.4.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below code will Take the extinction values, distance modulus and modulus error for each supernovae and run the photometory code for the estimation of apparent and absolute magnitude and also the delta m15 value....."
      ],
      "metadata": {
        "id": "nTgJGglndSut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.interpolate import UnivariateSpline\n",
        "from astropy.stats import sigma_clipped_stats\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load your ENHANCED dataset\n",
        "input_path = \"/content/drive/MyDrive/apparent magnitude data/cfa3_data_table.xlsx\"\n",
        "df = pd.read_excel(input_path)\n",
        "\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "print(\"Distance columns found:\", [col for col in df.columns if 'MU' in col.upper()])\n",
        "\n",
        "# Standard Cardelli 1989 extinction coefficients (R_V = 3.1)\n",
        "ext_coeffs = {'U': 1.664, 'B': 1.321, 'V': 1.000, 'R': 0.782, 'I': 0.601}\n",
        "\n",
        "def fit_single_filter(jd, mag, mag_err, filter_name):\n",
        "    \"\"\"ROBUST peak fitting with outlier rejection\"\"\"\n",
        "    try:\n",
        "        # Filter good data points\n",
        "        mask = (~np.isnan(jd)) & (~np.isnan(mag)) & (~np.isnan(mag_err)) & (mag_err < 0.5)\n",
        "        if np.sum(mask) < 8:\n",
        "            return np.nan, np.nan\n",
        "\n",
        "        jd_clean, mag_clean, mag_err_clean = jd[mask], mag[mask], mag_err[mask]\n",
        "        n_points = len(jd_clean)\n",
        "        s_smooth = max(0.1 * n_points, 0.5)\n",
        "\n",
        "        # *** OUTLIER REJECTION: Sigma clip input data first ***\n",
        "        mag_mean, mag_median, mag_std = sigma_clipped_stats(mag_clean)\n",
        "        input_mask = np.abs(mag_clean - mag_median) < 3 * mag_std\n",
        "        jd_clean = jd_clean[input_mask]\n",
        "        mag_clean = mag_clean[input_mask]\n",
        "        mag_err_clean = mag_err_clean[input_mask]\n",
        "\n",
        "        if len(jd_clean) < 6:  # Need minimum after cleaning\n",
        "            return np.nan, np.nan\n",
        "\n",
        "        # Smoother data\n",
        "        mag_smooth = np.convolve(mag_clean, np.ones(5)/5, mode='same')\n",
        "        jd_range = jd_clean.max() - jd_clean.min()\n",
        "        fine_jd = np.linspace(jd_clean.min() - 0.1*jd_range,\n",
        "                             jd_clean.max() + 0.1*jd_range, 2000)\n",
        "\n",
        "        spline = UnivariateSpline(jd_clean, mag_smooth, k=3, s=s_smooth)\n",
        "        fine_mag = spline(fine_jd)\n",
        "\n",
        "        central_mask = (fine_jd > np.percentile(fine_jd, 15)) & \\\n",
        "                      (fine_jd < np.percentile(fine_jd, 85))\n",
        "        if np.sum(central_mask) < 100:\n",
        "            return np.nan, np.nan\n",
        "\n",
        "        peak_idx = np.argmin(fine_mag[central_mask])\n",
        "        mag_peak = fine_mag[central_mask][peak_idx]\n",
        "\n",
        "        # *** PHYSICAL REALISM CHECK ***\n",
        "        if mag_peak < 5 or mag_peak > 25:  # Impossible peak magnitudes\n",
        "            return np.nan, np.nan\n",
        "\n",
        "        # Monte Carlo\n",
        "        n_iter = 3000\n",
        "        mag_peak_sim = []\n",
        "\n",
        "        for _ in range(n_iter):\n",
        "            mag_sim = mag_clean + np.random.normal(0, mag_err_clean)\n",
        "            try:\n",
        "                spline_sim = UnivariateSpline(jd_clean, mag_sim, k=3, s=s_smooth)\n",
        "                fine_mag_sim = spline_sim(fine_jd)\n",
        "                peak_idx_sim = np.argmin(fine_mag_sim[central_mask])\n",
        "                sim_peak = fine_mag_sim[central_mask][peak_idx_sim]\n",
        "\n",
        "                # Reject unrealistic simulations\n",
        "                if 5 < sim_peak < 25:\n",
        "                    mag_peak_sim.append(sim_peak)\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        if len(mag_peak_sim) < 20:\n",
        "            return np.nan, np.nan\n",
        "\n",
        "        mag_peak_sim = np.array(mag_peak_sim)\n",
        "        mag_peak_mean, _, mag_peak_std = sigma_clipped_stats(mag_peak_sim)\n",
        "\n",
        "        # *** FINAL VALIDATION ***\n",
        "        if mag_peak_mean < 5 or mag_peak_mean > 25 or mag_peak_std > 2.0:\n",
        "            return np.nan, np.nan\n",
        "\n",
        "        return mag_peak_mean, mag_peak_std\n",
        "\n",
        "    except:\n",
        "        return np.nan, np.nan\n",
        "\n",
        "def fit_b_delta_m15(jd, mag, mag_err):\n",
        "    \"\"\"Robust Œîm15 for B-band\"\"\"\n",
        "    try:\n",
        "        mask = (~np.isnan(jd)) & (~np.isnan(mag)) & (~np.isnan(mag_err)) & (mag_err < 0.5)\n",
        "        if np.sum(mask) < 8:\n",
        "            return np.nan, np.nan\n",
        "\n",
        "        jd_clean, mag_clean, mag_err_clean = jd[mask], mag[mask], mag_err[mask]\n",
        "\n",
        "        # Sigma clip input\n",
        "        mag_mean, mag_median, mag_std = sigma_clipped_stats(mag_clean)\n",
        "        input_mask = np.abs(mag_clean - mag_median) < 3 * mag_std\n",
        "        jd_clean = jd_clean[input_mask]\n",
        "        mag_clean = mag_clean[input_mask]\n",
        "        mag_err_clean = mag_err_clean[input_mask]\n",
        "\n",
        "        if len(jd_clean) < 6:\n",
        "            return np.nan, np.nan\n",
        "\n",
        "        n_points = len(jd_clean)\n",
        "        s_smooth = max(0.1 * n_points, 0.5)\n",
        "\n",
        "        mag_smooth = np.convolve(mag_clean, np.ones(5)/5, mode='same')\n",
        "        jd_range = jd_clean.max() - jd_clean.min()\n",
        "        fine_jd = np.linspace(jd_clean.min() - 0.1*jd_range,\n",
        "                             jd_clean.max() + 0.1*jd_range, 2000)\n",
        "\n",
        "        spline = UnivariateSpline(jd_clean, mag_smooth, k=3, s=s_smooth)\n",
        "        fine_mag = spline(fine_jd)\n",
        "\n",
        "        central_mask = (fine_jd > np.percentile(fine_jd, 15)) & \\\n",
        "                      (fine_jd < np.percentile(fine_jd, 85))\n",
        "        peak_idx = np.argmin(fine_mag[central_mask])\n",
        "        jd_peak = fine_jd[central_mask][peak_idx]\n",
        "\n",
        "        dm15 = spline(jd_peak + 15) - np.min(fine_mag[central_mask])\n",
        "\n",
        "        # Physical check\n",
        "        if dm15 < 0.5 or dm15 > 3.0:  # Impossible decline rates\n",
        "            return np.nan, np.nan\n",
        "\n",
        "        n_iter = 3000\n",
        "        dm15_sim = []\n",
        "        for _ in range(n_iter):\n",
        "            mag_sim = mag_clean + np.random.normal(0, mag_err_clean)\n",
        "            try:\n",
        "                spline_sim = UnivariateSpline(jd_clean, mag_sim, k=3, s=s_smooth)\n",
        "                fine_mag_sim = spline_sim(fine_jd)\n",
        "                peak_idx_sim = np.argmin(fine_mag_sim[central_mask])\n",
        "                jd_peak_sim = fine_jd[central_mask][peak_idx_sim]\n",
        "                sim_dm15 = spline_sim(jd_peak_sim + 15) - np.min(fine_mag_sim[central_mask])\n",
        "\n",
        "                if 0.5 < sim_dm15 < 3.0:\n",
        "                    dm15_sim.append(sim_dm15)\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        if len(dm15_sim) < 20:\n",
        "            return np.nan, np.nan\n",
        "\n",
        "        dm15_sim = np.array(dm15_sim)\n",
        "        dm15_mean, _, dm15_std = sigma_clipped_stats(dm15_sim)\n",
        "\n",
        "        if dm15_mean < 0.5 or dm15_mean > 3.0 or dm15_std > 0.5:\n",
        "            return np.nan, np.nan\n",
        "\n",
        "        return dm15_mean, dm15_std\n",
        "\n",
        "    except:\n",
        "        return np.nan, np.nan\n",
        "\n",
        "# Filter SNe with SH0ES distances\n",
        "valid_sne = df.dropna(subset=['MU_SH0ES', 'MU_SH0ES_ERR_DIAG'])['SN'].unique()\n",
        "print(f\"\\n‚úÖ Found {len(valid_sne)} SNe with SH0ES distances\")\n",
        "\n",
        "# Process ALL SNe (remove [:50] limit)\n",
        "results = []\n",
        "rejected_count = {'U':0, 'B':0, 'V':0, 'R':0, 'I':0, 'dm15':0}\n",
        "\n",
        "for sn in tqdm(valid_sne, desc=\"üî• Processing ALL SNe\"):\n",
        "    sn_data = df[df['SN'] == sn].copy()\n",
        "\n",
        "    mu = sn_data['MU_SH0ES'].iloc[0]\n",
        "    mu_err = sn_data['MU_SH0ES_ERR_DIAG'].iloc[0]\n",
        "    mwebv = sn_data.get('MWEBV', pd.Series([0.0])).iloc[0]\n",
        "\n",
        "    sn_results = {\n",
        "        'SN': sn, 'MU_SH0ES': mu, 'MU_ERR': mu_err, 'MWEBV': mwebv\n",
        "    }\n",
        "\n",
        "    for filter_name in ['U', 'B', 'V', 'R', 'I']:\n",
        "        filter_data = sn_data[sn_data['Filter'] == filter_name]\n",
        "\n",
        "        if len(filter_data) >= 8:\n",
        "            jd = filter_data['MJD'].values\n",
        "            mag = filter_data['STDMAG'].values\n",
        "            mag_err = filter_data['dMAG'].values\n",
        "\n",
        "            app_peak, app_peak_err = fit_single_filter(jd, mag, mag_err, filter_name)\n",
        "\n",
        "            if not np.isnan(app_peak):\n",
        "                A_lambda = ext_coeffs.get(filter_name, 1.0) * abs(mwebv)\n",
        "                abs_mag = app_peak - mu - A_lambda\n",
        "\n",
        "                # *** ABSOLUTE MAG OUTLIER REJECTION ***\n",
        "                if abs_mag < -25 or abs_mag > -15:  # Type Ia range\n",
        "                    rejected_count[filter_name] += 1\n",
        "                else:\n",
        "                    sn_results.update({\n",
        "                        f'{filter_name}_app_peak': app_peak,\n",
        "                        f'{filter_name}_app_peak_err': app_peak_err,\n",
        "                        f'{filter_name}_abs_mag': abs_mag,\n",
        "                        f'{filter_name}_abs_mag_err': np.sqrt(app_peak_err**2 + mu_err**2)\n",
        "                    })\n",
        "\n",
        "    # B-band Œîm15\n",
        "    b_data = sn_data[sn_data['Filter'] == 'B']\n",
        "    if len(b_data) >= 8:\n",
        "        jd_b = b_data['MJD'].values\n",
        "        mag_b = b_data['STDMAG'].values\n",
        "        mag_err_b = b_data['dMAG'].values\n",
        "\n",
        "        dm15_b, dm15_err_b = fit_b_delta_m15(jd_b, mag_b, mag_err_b)\n",
        "        if not np.isnan(dm15_b):\n",
        "            sn_results['B_dm15'] = dm15_b\n",
        "            sn_results['B_dm15_err'] = dm15_err_b\n",
        "        else:\n",
        "            rejected_count['dm15'] += 1\n",
        "\n",
        "    results.append(sn_results)\n",
        "\n",
        "# Results\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_excel('cfa3_ubvri_cleaned.xlsx', index=False)\n",
        "\n",
        "print(f\"\\nüéâ SAVED {len(results_df)} SNe to cfa3_ubvri_cleaned.xlsx\")\n",
        "print(f\"Rejected: U={rejected_count['U']}, B={rejected_count['B']}, V={rejected_count['V']}, R={rejected_count['R']}, I={rejected_count['I']}, dm15={rejected_count['dm15']}\")\n",
        "\n",
        "# CLEAN VALIDATION\n",
        "print(\"\\nüìä CLEANED UBVRI RESULTS:\")\n",
        "for band in ['U', 'B', 'V', 'R', 'I']:\n",
        "    abs_col = f'{band}_abs_mag'\n",
        "    if abs_col in results_df.columns:\n",
        "        valid = results_df[abs_col].dropna()\n",
        "        if len(valid) > 0:\n",
        "            print(f\"{band}: {len(valid)} SNe, mean={valid.mean():.3f}¬±{valid.std():.3f} (range: {valid.min():.2f} to {valid.max():.2f})\")\n",
        "\n",
        "print(\"\\nüìä CLEANED B-BAND Œîm15:\")\n",
        "b_dm15 = results_df['B_dm15'].dropna()\n",
        "if len(b_dm15) > 0:\n",
        "    print(f\"Œîm15(B): {len(b_dm15)} SNe, mean={b_dm15.mean():.3f}¬±{b_dm15.std():.3f}\")\n",
        "\n",
        "print(\"\\n‚úÖ OUTLIERS REMOVED: Only physical Type Ia magnitudes kept!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wN9CuMWQaEi0",
        "outputId": "f0161d7e-49d6-4ffd-81ca-5438670366ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (11499, 8)\n",
            "Distance columns found: ['MU_SH0ES', 'MU_SH0ES_ERR_DIAG']\n",
            "\n",
            "‚úÖ Found 112 SNe with SH0ES distances\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üî• Processing ALL SNe:  15%|‚ñà‚ñå        | 17/112 [00:14<01:06,  1.42it/s]/tmp/ipython-input-66375940.py:46: UserWarning: \n",
            "The maximal number of iterations maxit (set to 20 by the program)\n",
            "allowed for finding a smoothing spline with fp=s has been reached: s\n",
            "too small.\n",
            "There is an approximation returned but the corresponding weighted sum\n",
            "of squared residuals does not satisfy the condition abs(fp-s)/s < tol.\n",
            "  spline = UnivariateSpline(jd_clean, mag_smooth, k=3, s=s_smooth)\n",
            "üî• Processing ALL SNe:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 61/112 [00:48<00:53,  1.04s/it]/tmp/ipython-input-66375940.py:68: UserWarning: \n",
            "The maximal number of iterations maxit (set to 20 by the program)\n",
            "allowed for finding a smoothing spline with fp=s has been reached: s\n",
            "too small.\n",
            "There is an approximation returned but the corresponding weighted sum\n",
            "of squared residuals does not satisfy the condition abs(fp-s)/s < tol.\n",
            "  spline_sim = UnivariateSpline(jd_clean, mag_sim, k=3, s=s_smooth)\n",
            "üî• Processing ALL SNe: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 112/112 [01:24<00:00,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üéâ SAVED 112 SNe to cfa3_ubvri_cleaned.xlsx\n",
            "Rejected: U=0, B=1, V=1, R=0, I=0, dm15=57\n",
            "\n",
            "üìä CLEANED UBVRI RESULTS:\n",
            "U: 24 SNe, mean=-18.584¬±0.767 (range: -19.52 to -16.29)\n",
            "B: 55 SNe, mean=-18.275¬±0.687 (range: -19.27 to -15.56)\n",
            "V: 66 SNe, mean=-18.535¬±0.524 (range: -19.31 to -16.00)\n",
            "R: 19 SNe, mean=-18.836¬±0.254 (range: -19.25 to -18.34)\n",
            "I: 14 SNe, mean=-18.584¬±0.205 (range: -18.86 to -18.24)\n",
            "\n",
            "üìä CLEANED B-BAND Œîm15:\n",
            "Œîm15(B): 22 SNe, mean=1.098¬±0.354\n",
            "\n",
            "‚úÖ OUTLIERS REMOVED: Only physical Type Ia magnitudes kept!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}