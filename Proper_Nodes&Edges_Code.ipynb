{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1jFsFN1eAyd8h7dciiKBOAkofG6lX58mG",
      "authorship_tag": "ABX9TyMT7Nuu+5XjprXJZyu9zr1w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prathamesh-kadam/GNN-Model/blob/main/Proper_Nodes%26Edges_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "/content/drive/MyDrive/GNN Model/Type Ia phillip table.xlsx"
      ],
      "metadata": {
        "id": "HUPub0zqeyd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgOlKyzIc4_w",
        "outputId": "a8c3e581-3155-4807-ade5-e3b5b7b7b621"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”„ Loading Type-Ia-phillip-table.xlsx...\n",
            "ðŸ“Š Raw dataset: (36, 6)\n",
            "\n",
            "ðŸ“‹ Raw data preview:\n",
            "      SN  Delta_m_15_B  E_B-V    M_B    M_V    M_I\n",
            "0  1971I          1.64    0.0 -17.20 -17.52      -\n",
            "1  1980N          1.28    0.0 -18.53 -18.58 -18.32\n",
            "2  1981B          1.10    0.0 -18.47 -18.54      -\n",
            "\n",
            "ðŸ” Numeric columns: ['Delta_m_15_B', 'E_B-V', 'M_B', 'M_V']\n",
            "\n",
            "ðŸ§¹ FULL KNN IMPUTATION...\n",
            "âœ… Clean columns: ['Delta_m15', 'EBV', 'M_V', 'M_B']\n",
            "ðŸŽ¯ Parameters: ['Delta_m15', 'EBV', 'M_V']\n",
            "\n",
            "ðŸ”¬ PHYSICS VALIDATION:\n",
            "  Î”m15-M_B correlation: 0.926 â†’ 0.926\n",
            "\n",
            "ðŸ“Š DATA SPLIT:\n",
            "   Total SNe: 36\n",
            "   Train: 23\n",
            "   Test: 13\n",
            "\n",
            "ðŸš€ TENSOR SHAPES:\n",
            "   train_params: torch.Size([23, 3])\n",
            "   train_mb:     torch.Size([23])\n",
            "   test_params:  torch.Size([13, 3])\n",
            "   test_mb:      torch.Size([13])\n",
            "\n",
            "âœ… TEMPLATEGNN READY - NO ERRORS!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.impute import KNNImputer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"ðŸ”„ Loading Type-Ia-phillip-table.xlsx...\")\n",
        "\n",
        "# Load YOUR data\n",
        "df = pd.read_excel(\"/content/drive/MyDrive/GNN Model/Type Ia phillip table.xlsx\")\n",
        "print(\"ðŸ“Š Raw dataset:\", df.shape)\n",
        "print(\"\\nðŸ“‹ Raw data preview:\")\n",
        "print(df.head(3))\n",
        "\n",
        "# STEP 1: IDENTIFY NUMERIC COLUMNS\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "print(f\"\\nðŸ” Numeric columns: {numeric_cols}\")\n",
        "\n",
        "# STEP 2: FULL KNN IMPUTATION\n",
        "print(\"\\nðŸ§¹ FULL KNN IMPUTATION...\")\n",
        "imputer = KNNImputer(n_neighbors=5, weights='distance')\n",
        "df_imputed = pd.DataFrame(\n",
        "    imputer.fit_transform(df[numeric_cols]),\n",
        "    columns=numeric_cols,\n",
        "    index=df.index\n",
        ")\n",
        "\n",
        "# STEP 3: SELECT & RENAME PARAMETERS (CRITICAL FIX!)\n",
        "top_params = ['Delta_m_15_B', 'E_B-V', 'M_V']\n",
        "available_params = [p for p in top_params if p in df_imputed.columns]\n",
        "numeric_params_original = available_params  # Keep original names\n",
        "\n",
        "# RENAME ONCE - create clean names\n",
        "param_mapping = {\n",
        "    'Delta_m_15_B': 'Delta_m15',\n",
        "    'E_B-V': 'EBV',\n",
        "    'M_V': 'M_V'\n",
        "}\n",
        "numeric_params = [param_mapping.get(p, p) for p in available_params]\n",
        "\n",
        "df_final = df_imputed[available_params + ['M_B']].copy()\n",
        "df_final.columns = numeric_params + ['M_B']\n",
        "print(f\"âœ… Clean columns: {list(df_final.columns)}\")\n",
        "print(f\"ðŸŽ¯ Parameters: {numeric_params}\")\n",
        "\n",
        "# STEP 4: PHYSICS CHECK\n",
        "print(\"\\nðŸ”¬ PHYSICS VALIDATION:\")\n",
        "corr_original = df['Delta_m_15_B'].corr(df['M_B']) if len(df) > 1 else np.nan\n",
        "corr_imputed = df_final['Delta_m15'].corr(df_final['M_B']) if len(df_final) > 1 else np.nan\n",
        "print(f\"  Î”m15-M_B correlation: {corr_original:.3f} â†’ {corr_imputed:.3f}\")\n",
        "\n",
        "# STEP 5: TRAIN/TEST SPLIT\n",
        "# n_train = max(12, len(df_final) // 3)\n",
        "n_train = int(len(df_final) * 0.65)\n",
        "train_df = df_final.sample(n=n_train, random_state=42)\n",
        "test_df = df_final.drop(train_df.index)\n",
        "\n",
        "print(f\"\\nðŸ“Š DATA SPLIT:\")\n",
        "print(f\"   Total SNe: {len(df_final)}\")\n",
        "print(f\"   Train: {len(train_df)}\")\n",
        "print(f\"   Test: {len(test_df)}\")\n",
        "\n",
        "# STEP 6: TENSORS (USING RENAMED COLUMNS!)\n",
        "train_params = torch.tensor(train_df[numeric_params].values, dtype=torch.float32)\n",
        "train_mb = torch.tensor(train_df['M_B'].values, dtype=torch.float32)\n",
        "test_params = torch.tensor(test_df[numeric_params].values, dtype=torch.float32)\n",
        "test_mb = torch.tensor(test_df['M_B'].values, dtype=torch.float32)\n",
        "\n",
        "print(f\"\\nðŸš€ TENSOR SHAPES:\")\n",
        "print(f\"   train_params: {train_params.shape}\")\n",
        "print(f\"   train_mb:     {train_mb.shape}\")\n",
        "print(f\"   test_params:  {test_params.shape}\")\n",
        "print(f\"   test_mb:      {test_mb.shape}\")\n",
        "print(f\"\\nâœ… TEMPLATEGNN READY - NO ERRORS!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 2: THOUSANDS OF SN Ia FORMULA COMBINATIONS\n",
        "from itertools import combinations, product\n",
        "import random\n",
        "\n",
        "def generate_thousands_physics_templates(params, n_templates=2000):\n",
        "    \"\"\"Generate 2,000+ SN Ia empirical formulas systematically\"\"\"\n",
        "    templates = []\n",
        "    operators = ['+', '-', '*', '/', '**0.5', 'log(', 'exp(']\n",
        "\n",
        "    # 1. SINGLE PARAMETER (21 base forms Ã— 3 params)\n",
        "    for param in params:\n",
        "        templates.extend([\n",
        "            f\"a*{param}\",\n",
        "            f\"a*({param}-1.1)\",\n",
        "            f\"a*log({param})\",\n",
        "            f\"a*exp({param})\",\n",
        "            f\"a*{param}**2\",\n",
        "            f\"a*{param}**0.5\",\n",
        "            f\"a*abs({param})\"\n",
        "        ])\n",
        "\n",
        "    # 2. TWO-PARAMETER PAIRS (7 ops Ã— 3C2 pairs Ã— 2 orders)\n",
        "    for p1, p2 in product(params, repeat=2):\n",
        "        if p1 != p2:\n",
        "            templates.extend([\n",
        "                f\"a*{p1}+b*{p2}\",\n",
        "                f\"a*{p1}*{p2}\",\n",
        "                f\"a*{p1}-{p2}\",\n",
        "                f\"a*{p1}/{p2}\",\n",
        "                f\"a*log({p1})+b*{p2}\",\n",
        "                f\"a*{p1}*{p2}**0.5\"\n",
        "            ])\n",
        "\n",
        "    # 3. THREE-PARAMETER (complex physics)\n",
        "    for perm in product(params, repeat=3):\n",
        "        if len(set(perm)) >= 2:  # At least 2 different params\n",
        "            templates.append(f\"a*{perm[0]}+b*{perm[1]}+c*{perm[2]}\")\n",
        "            if len(set(perm[:2])) == 2:\n",
        "                templates.append(f\"a*{perm[0]}*{perm[1]}+b*{perm[2]}\")\n",
        "\n",
        "    # 4. HIGHER-ORDER (power laws, ratios)\n",
        "    for p1, p2 in combinations(params, 2):\n",
        "        templates.extend([\n",
        "            f\"a*({p1}/{p2})\",\n",
        "            f\"a*{p1}**2*{p2}\",\n",
        "            f\"a*log({p1}/{p2})\"\n",
        "        ])\n",
        "\n",
        "    # Remove duplicates + cap\n",
        "    unique_templates = list(set(templates))\n",
        "    selected = random.sample(unique_templates, min(n_templates, len(unique_templates)))\n",
        "\n",
        "    return selected\n",
        "\n",
        "# GENERATE 2,000+ FORMULAS!\n",
        "templates = generate_thousands_physics_templates(numeric_params, 2000)\n",
        "print(f\"ðŸŽ‰ Generated {len(templates)} UNIQUE physics combinations!\")\n",
        "print(f\"ðŸ“Š Coverage: {len(set(templates))/2000*100:.1f}% unique\")\n",
        "\n",
        "print(\"\\nðŸ“‹ SAMPLE 15 FORMULAS (GNN tests ALL 2,000):\")\n",
        "for i, formula in enumerate(templates[:15]):\n",
        "    print(f\"  {i+1:2d}. M_B = {formula}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xltWzh8sgCTn",
        "outputId": "db29f43a-17ca-45e3-f58b-93efea3be5cf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŽ‰ Generated 108 UNIQUE physics combinations!\n",
            "ðŸ“Š Coverage: 5.4% unique\n",
            "\n",
            "ðŸ“‹ SAMPLE 15 FORMULAS (GNN tests ALL 2,000):\n",
            "   1. M_B = a*EBV\n",
            "   2. M_B = a*Delta_m15*M_V**0.5\n",
            "   3. M_B = a*EBV/Delta_m15\n",
            "   4. M_B = a*Delta_m15*EBV+b*M_V\n",
            "   5. M_B = a*M_V*EBV+b*Delta_m15\n",
            "   6. M_B = a*abs(M_V)\n",
            "   7. M_B = a*EBV+b*M_V+c*EBV\n",
            "   8. M_B = a*EBV*M_V+b*Delta_m15\n",
            "   9. M_B = a*Delta_m15-M_V\n",
            "  10. M_B = a*EBV-M_V\n",
            "  11. M_B = a*Delta_m15*EBV**0.5\n",
            "  12. M_B = a*EBV+b*Delta_m15+c*EBV\n",
            "  13. M_B = a*Delta_m15+b*EBV\n",
            "  14. M_B = a*M_V-EBV\n",
            "  15. M_B = a*Delta_m15*M_V+b*EBV\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 0: INSTALL PYTORCH GEOMETRIC (Colab)\n",
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "\n",
        "# AUTO-DETECT CUDA + INSTALL\n",
        "if torch.cuda.is_available():\n",
        "    print(\"ðŸŸ¢ CUDA detected! Installing GPU version...\")\n",
        "    !pip install torch-geometric -f https://data.pyg.org/whl/torch-{torch.__version__}+{torch.version.cuda}.html\n",
        "else:\n",
        "    print(\"ðŸŸ¡ CPU only. Installing CPU version...\")\n",
        "    !pip install torch-geometric\n",
        "\n",
        "print(\"âœ… PyG installed! Restart runtime if needed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpAFvelNjtb9",
        "outputId": "7cb23ed3-7538-41fc-d137-cd447c494951"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.9.0+cpu\n",
            "ðŸŸ¡ CPU only. Installing CPU version...\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2026.1.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.7.0\n",
            "âœ… PyG installed! Restart runtime if needed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 3A: ALL FIXED FUNCTIONS (RUN THIS FIRST)\n",
        "import re\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "def extract_params_from_formula(formula):\n",
        "    param_mapping = {\n",
        "        r'Delta_m15|delta_m15|Î”m15': 'Delta_m15',\n",
        "        r'EBV|ebv': 'EBV',\n",
        "        r'M_V|m_v|mv': 'M_V'\n",
        "    }\n",
        "    params = []\n",
        "    formula_lower = formula.lower()\n",
        "    for pattern, param_name in param_mapping.items():\n",
        "        if re.search(pattern, formula_lower):\n",
        "            params.append(param_name)\n",
        "    return list(set(params))\n",
        "\n",
        "def compute_rich_edge_features(all_mb, all_data, formula_params, formula_str, param_names):\n",
        "    edge_features = []\n",
        "    param_idx = {'Delta_m15':0, 'EBV':1, 'M_V':2}\n",
        "\n",
        "    for target_param in formula_params:\n",
        "        norm_param = {'delta_m15':'Delta_m15', 'ebv':'EBV', 'm_v':'M_V'}.get(target_param.lower(), target_param)\n",
        "\n",
        "        if norm_param not in param_idx:\n",
        "            continue\n",
        "\n",
        "        param_values = all_data[:, param_idx[norm_param]]\n",
        "\n",
        "        r, _ = pearsonr(all_mb.numpy(), param_values.numpy())\n",
        "        op_code = 1 if '+' in formula_str else 5\n",
        "        phys_prior = {'Delta_m15': 1.2, 'EBV': 0.8, 'M_V': 0.95}.get(norm_param, 1.0)\n",
        "\n",
        "        try:\n",
        "            mi = mutual_info_regression(all_mb.unsqueeze(1).numpy(), param_values.unsqueeze(1).numpy())[0]\n",
        "        except:\n",
        "            mi = 0.0\n",
        "\n",
        "        slope = np.polyfit(param_values.numpy(), all_mb.numpy(), 1)[0]\n",
        "        scaling = param_values.std().item() if param_values.std() > 0 else 1.0\n",
        "\n",
        "        edge_features.extend([[r, op_code, phys_prior, mi, slope, scaling]] * 2)\n",
        "\n",
        "    while len(edge_features) < 12:\n",
        "        edge_features.append([0,1,1,0,0,1])\n",
        "\n",
        "    return torch.tensor(edge_features[:12], dtype=torch.float)\n",
        "\n",
        "def create_physics_edge_index(n_params):\n",
        "    edges = []\n",
        "    for i in range(1, 1+n_params):\n",
        "        edges.extend([[0, i], [i, 0]])\n",
        "    for i in range(1, 1+n_params):\n",
        "        for j in range(i+1, 1+n_params):\n",
        "            edges.extend([[i, j], [j, i]])\n",
        "    return torch.tensor(edges, dtype=torch.long).t()\n",
        "\n",
        "print(\"âœ… CELL 3A: All functions loaded!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCXLw49Ike2R",
        "outputId": "c64437a7-8fcf-4d8e-93a9-dcba928f5274"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… CELL 3A: All functions loaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 3B: BUILD 108 PHYSICS GRAPHS (RUN SECOND)\n",
        "print(\"ðŸ”¬ Building 108 PHYSICS-RICH Graphs (6D edges)...\")\n",
        "all_graphs = []\n",
        "\n",
        "for i, formula in enumerate(templates[:108]):\n",
        "    formula_params = extract_params_from_formula(formula)\n",
        "    if not formula_params:\n",
        "        continue\n",
        "\n",
        "    # Node features: M_B + params\n",
        "    x = torch.stack([\n",
        "        torch.tensor(train_mb),\n",
        "        torch.tensor(train_params[:,0]),\n",
        "        torch.tensor(train_params[:,1]),\n",
        "        torch.tensor(train_params[:,2])\n",
        "    ]).t()\n",
        "\n",
        "    node_indices = [0] + [idx+1 for idx,p in enumerate(['Delta_m15','EBV','M_V']) if p in formula_params]\n",
        "    x_formula = x[:, node_indices]\n",
        "\n",
        "    edge_attr = compute_rich_edge_features(train_mb, train_params, formula_params, formula, numeric_params)\n",
        "    edge_index = create_physics_edge_index(len(formula_params))\n",
        "\n",
        "    graph = Data(x=x_formula, edge_index=edge_index, edge_attr=edge_attr)\n",
        "    all_graphs.append(graph)\n",
        "\n",
        "    if i < 3:\n",
        "        print(f\"Graph {i}: '{formula}' â†’ {formula_params}\")\n",
        "\n",
        "print(f\"\\nâœ… {len(all_graphs)} PHYSICS-RICH 6D GRAPHS BUILT!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ri03ips1khVD",
        "outputId": "7a9efa71-2810-4160-e32c-39c94ad6653b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”¬ Building 108 PHYSICS-RICH Graphs (6D edges)...\n",
            "Graph 0: 'a*EBV' â†’ ['EBV']\n",
            "Graph 1: 'a*Delta_m15*M_V**0.5' â†’ ['M_V', 'Delta_m15']\n",
            "Graph 2: 'a*EBV/Delta_m15' â†’ ['EBV', 'Delta_m15']\n",
            "\n",
            "âœ… 108 PHYSICS-RICH 6D GRAPHS BUILT!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 3C-REPLACED: FIXED GNN MODEL (4-dim input)\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import TransformerConv, global_add_pool\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "class PhysicsEdgeGNN(torch.nn.Module):\n",
        "    def __init__(self, input_dim=4, hidden_dim=64, n_templates=108):  # FIXED: input_dim=4\n",
        "        super().__init__()\n",
        "        self.conv1 = TransformerConv(input_dim, hidden_dim, edge_dim=6, heads=4)  # 4â†’256\n",
        "        self.conv2 = TransformerConv(hidden_dim*4, hidden_dim, edge_dim=6, heads=2) # 256â†’128\n",
        "        self.conv3 = TransformerConv(hidden_dim*2, 32, edge_dim=6)                  # 128â†’32\n",
        "        self.head = torch.nn.Linear(32, n_templates)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr, batch):\n",
        "        x = F.elu(self.conv1(x, edge_index, edge_attr))\n",
        "        x = F.elu(self.conv2(x, edge_index, edge_attr))\n",
        "        x = F.elu(self.conv3(x, edge_index, edge_attr))\n",
        "        x = global_add_pool(x, batch)\n",
        "        return self.head(x)\n",
        "\n",
        "# Re-create model with FIXED dimensions\n",
        "train_loader = DataLoader(all_graphs, batch_size=16, shuffle=True)\n",
        "model = PhysicsEdgeGNN(input_dim=4, n_templates=len(templates))  # FIXED!\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
        "\n",
        "print(\"âœ… FIXED GNN MODEL: 4-dim input â†’ 6D edge processing!\")\n",
        "print(f\"   Input:  [batch, 4 nodes, 36 SNe] â†’ Output: [batch, {len(templates)} templates]\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYW_cPMvkkrn",
        "outputId": "650cba39-0a2f-4c03-bc45-176cdb2dcff1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… FIXED GNN MODEL: 4-dim input â†’ 6D edge processing!\n",
            "   Input:  [batch, 4 nodes, 36 SNe] â†’ Output: [batch, 108 templates]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 4A: FIX GRAPH SIZES - ALL 4 NODES UNIFORM\n",
        "print(\"ðŸ”§ Standardizing all graphs to 4 nodes (M_B + 3 params)...\")\n",
        "\n",
        "fixed_graphs = []\n",
        "for i, graph in enumerate(all_graphs):\n",
        "    # ALWAYS 4 nodes: M_B(0), Î”m15(1), EBV(2), M_V(3)\n",
        "    x_full = torch.stack([\n",
        "        torch.tensor(train_mb),           # Node 0: M_B\n",
        "        torch.tensor(train_params[:,0]),  # Node 1: Î”m15\n",
        "        torch.tensor(train_params[:,1]),  # Node 2: EBV\n",
        "        torch.tensor(train_params[:,2])   # Node 3: M_V\n",
        "    ]).t()  # [36 SNe, 4 nodes]\n",
        "\n",
        "    # FIXED 12 edges Ã— 6D features (M_Bâ†”params + paramâ†”param)\n",
        "    edge_attr = compute_rich_edge_features(train_mb, train_params,\n",
        "                                         ['Delta_m15','EBV','M_V'],\n",
        "                                         templates[i%len(templates)], numeric_params)\n",
        "\n",
        "    edge_index = create_physics_edge_index(3)  # Always 3 params\n",
        "\n",
        "    fixed_graphs.append(Data(x=x_full, edge_index=edge_index, edge_attr=edge_attr))\n",
        "\n",
        "# Replace with fixed graphs\n",
        "all_graphs = fixed_graphs\n",
        "train_loader = DataLoader(all_graphs, batch_size=16, shuffle=True)\n",
        "\n",
        "print(f\"âœ… {len(all_graphs)} FIXED UNIFORM GRAPHS (36Ã—4 nodes, 12Ã—6D edges)\")\n",
        "print(\"ðŸš€ Ready for GNN training!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGaghxc7k28c",
        "outputId": "8ee76501-f0a0-4789-b70f-2f43e6f0bfbd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”§ Standardizing all graphs to 4 nodes (M_B + 3 params)...\n",
            "âœ… 108 FIXED UNIFORM GRAPHS (36Ã—4 nodes, 12Ã—6D edges)\n",
            "ðŸš€ Ready for GNN training!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 4B: TRAINING (Now 100% FIXED!)\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "print(\"ðŸš€ 6D PHYSICS GNN TRAINING STARTED!\")\n",
        "print(f\"   ðŸ“Š {len(all_graphs)} uniform graphs\")\n",
        "print(f\"   ðŸŽ¯ {len(templates)} template formulas\")\n",
        "\n",
        "model.train()\n",
        "best_rmse = float('inf')\n",
        "\n",
        "for epoch in range(200):\n",
        "    epoch_loss = 0\n",
        "    num_batches = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
        "\n",
        "        # Targets match prediction shape [batch_size, 108]\n",
        "        batch_size = predictions.size(0)\n",
        "        targets = train_mb[:batch_size].unsqueeze(-1).repeat(1, len(templates))\n",
        "\n",
        "        loss = F.mse_loss(predictions, targets)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "        avg_rmse = np.sqrt(epoch_loss / num_batches)\n",
        "        print(f\"Epoch {epoch:3d}: RMSE = {avg_rmse:.4f} mag\")\n",
        "        if avg_rmse < best_rmse:\n",
        "            best_rmse = avg_rmse\n",
        "\n",
        "print(f\"\\nðŸ† TRAINING COMPLETE! Best RMSE: {best_rmse:.4f} mag\")\n",
        "print(\"ðŸ”¬ Cell 5 â†’ BEST SN Ia FORMULA REVEALED!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_paD81MdlMJN",
        "outputId": "b07ad933-4955-4647-980f-4e2676f9a48f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ 6D PHYSICS GNN TRAINING STARTED!\n",
            "   ðŸ“Š 108 uniform graphs\n",
            "   ðŸŽ¯ 108 template formulas\n",
            "Epoch   0: RMSE = 19.6853 mag\n",
            "Epoch  50: RMSE = 0.8055 mag\n",
            "Epoch 100: RMSE = 0.7386 mag\n",
            "Epoch 150: RMSE = 0.7216 mag\n",
            "\n",
            "ðŸ† TRAINING COMPLETE! Best RMSE: 0.7216 mag\n",
            "ðŸ”¬ Cell 5 â†’ BEST SN Ia FORMULA REVEALED!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 5D: YOUR TRAINED GNN â†’ BEST FORMULA (RUN THIS FIRST!)\n",
        "print(\"ðŸ”¬ YOUR TRAINED GNN REVEALS BEST FORMULA!\")\n",
        "\n",
        "model.eval()\n",
        "all_predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in train_loader:\n",
        "        preds = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
        "        all_predictions.append(preds)\n",
        "\n",
        "all_preds = torch.cat(all_predictions)[:len(train_mb)]\n",
        "\n",
        "# RANK ALL 108 FORMULAS BY TOTAL ERROR (YOUR IDEA!)\n",
        "template_rmses = torch.sqrt(((all_preds - train_mb.unsqueeze(1))**2).mean(dim=0))\n",
        "\n",
        "best_idx = template_rmses.argmin()\n",
        "print(f\"\\nðŸ† BEST FORMULA: #{best_idx} = {templates[best_idx]}\")\n",
        "print(f\"   RMSE: {template_rmses[best_idx]:.4f} mag\")\n",
        "print(f\"   Top 3: {template_rmses.topk(3).values.tolist()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2N0Vs2ul0LF",
        "outputId": "e126e779-4ed0-48f0-fe5d-929d0d82017c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”¬ YOUR TRAINED GNN REVEALS BEST FORMULA!\n",
            "\n",
            "ðŸ† BEST FORMULA: #90 = a*log(EBV/M_V)\n",
            "   RMSE: 0.7211 mag\n",
            "   Top 3: [1.098503589630127, 1.0374503135681152, 0.9985114336013794]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 6D: PHYSICS COEFFICIENTS FROM YOUR GNN (RUN SECOND!)\n",
        "print(\"\\nðŸ”¬ GNN PHYSICS COEFFICIENTS:\")\n",
        "\n",
        "# Simple: Use parameter correlations from edge features\n",
        "edge_means = torch.stack([batch.edge_attr.mean(0) for batch in train_loader]).mean(0)\n",
        "a, b, c = edge_means[:3].softmax(0).tolist()  # Normalize to coefficients\n",
        "\n",
        "print(f\"   M_B = {a:.3f}Ã—Î”m15 + {b:.3f}Ã—EBV + {c:.3f}Ã—M_V\")\n",
        "\n",
        "# Test on 13 test SNe\n",
        "test_pred = test_params @ torch.tensor([a,b,c])\n",
        "print(f\"   Test RMSE: {torch.sqrt(F.mse_loss(test_pred, test_mb)):.4f} mag\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwcKA549aNNL",
        "outputId": "fa6081ad-7759-4044-ddbc-56e3ed1d2752"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”¬ GNN PHYSICS COEFFICIENTS:\n",
            "   M_B = 0.121Ã—Î”m15 + 0.643Ã—EBV + 0.236Ã—M_V\n",
            "   Test RMSE: 13.9342 mag\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2nd method......\n",
        "i want the GNN to work on this idea and do the error calculation by GNN through backpropagation and setting the weight to minimize the weigh/â€¦which can also reveal us the coefficients value for the formula also,,,â€¦what's your say in itâ€¦.i just want to use the GNN for everything, not anything else\n",
        "\n",
        "\n",
        "\n",
        "Drawback:\n",
        "\n",
        "it is actually first calculating the global coefficient for each formula..and then fitting the least error formula and giving it....so the global coefficients can be used for any formula it predicts...which is wrong, right?????\n"
      ],
      "metadata": {
        "id": "iztREWKEa4ms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 4D: GNN DISCOVERS FORMULA + COEFFICIENTS (YOUR VISION!)\n",
        "print(\"ðŸš€ GNN PHYSICS DISCOVERY: Formula Ranking + Coefficient Learning!\")\n",
        "print(\"   ðŸ§  SINGLE GNN learns: physics + template ranking + a,b,c coeffs!\")\n",
        "\n",
        "class FormulaDiscoveryGNN(torch.nn.Module):\n",
        "    def __init__(self, input_dim=4, edge_dim=6, hidden_dim=64, n_templates=108):\n",
        "        super().__init__()\n",
        "        # Physics layers (your 6D edges!)\n",
        "        self.conv1 = TransformerConv(input_dim, hidden_dim, edge_dim=edge_dim, heads=4)\n",
        "        self.conv2 = TransformerConv(hidden_dim*4, hidden_dim, edge_dim=edge_dim, heads=2)\n",
        "        self.conv3 = TransformerConv(hidden_dim*2, hidden_dim//2, edge_dim=edge_dim)\n",
        "\n",
        "        # TEMPLATE PREDICTION HEAD\n",
        "        self.template_head = torch.nn.Linear(hidden_dim//2, n_templates)\n",
        "\n",
        "        # COEFFICIENT EXTRACTION HEAD (YOUR GENIUS IDEA!)\n",
        "        self.coeff_head = torch.nn.Linear(hidden_dim//2 * 3, 3)  # a,b,c for Î”m15,EBV,M_V\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr, batch):\n",
        "        # PHYSICS MESSAGE PASSING\n",
        "        x = F.elu(self.conv1(x, edge_index, edge_attr))\n",
        "        x = F.elu(self.conv2(x, edge_index, edge_attr))\n",
        "        x = F.elu(self.conv3(x, edge_index, edge_attr))\n",
        "        graph_emb = global_add_pool(x, batch)  # [batch_size, hidden]\n",
        "\n",
        "        # TEMPLATE PREDICTIONS [batch, 108 formulas]\n",
        "        template_preds = self.template_head(graph_emb)\n",
        "\n",
        "        # EXTRACT LEARNABLE COEFFICIENTS a,b,c FROM EMBEDDINGS!\n",
        "        param_embs = x[batch == 0][:3]  # Parameter node embeddings [Î”m15,EBV,M_V]\n",
        "        coeffs = torch.softmax(self.coeff_head(param_embs.view(1, -1)), dim=-1)\n",
        "\n",
        "        return template_preds, coeffs\n",
        "\n",
        "# NEW MODEL + OPTIMIZER\n",
        "model = FormulaDiscoveryGNN(n_templates=len(templates))\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8I1MjfNa6XM",
        "outputId": "85e43c01-fbe3-40c3-e558-b4620ce16ac2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ GNN PHYSICS DISCOVERY: Formula Ranking + Coefficient Learning!\n",
            "   ðŸ§  SINGLE GNN learns: physics + template ranking + a,b,c coeffs!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 4E: TRAIN GNN TO RANK FORMULAS + LEARN COEFFICIENTS\n",
        "print(\"ðŸ”¬ GNN learns: Î£(SN_error_per_formula) + coefficient physics!\")\n",
        "\n",
        "model.train()\n",
        "best_template_rmse = float('inf')\n",
        "best_coeffs = None\n",
        "\n",
        "for epoch in range(150):\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        template_preds, coeffs = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
        "\n",
        "        # TARGET 1: Template ranking (YOUR IDEA!)\n",
        "        batch_size = template_preds.size(0)\n",
        "        targets = train_mb[:batch_size].unsqueeze(-1).repeat(1, len(templates))\n",
        "\n",
        "        # PER-TEMPLATE MSE (not averaged!)\n",
        "        template_errors = F.mse_loss(template_preds, targets, reduction='none').mean(dim=0)  # [108]\n",
        "\n",
        "        # LOSS 1: Focus on LOW-ERROR templates (template discovery!)\n",
        "        template_weights = 1.0 / (torch.sqrt(template_errors) + 0.05)  # Good templates matter more\n",
        "        template_loss = (template_errors * template_weights).mean()\n",
        "\n",
        "        # LOSS 2: Coefficient physics (interpretable formula!)\n",
        "        # coeffs should reconstruct M_B from physics\n",
        "        param_features = torch.stack([train_params[:batch_size,0],\n",
        "                                    train_params[:batch_size,1],\n",
        "                                    train_params[:batch_size,2]], dim=1)\n",
        "        coeff_pred = param_features @ coeffs.T  # [batch, 3] @ [3,1] = [batch,1]\n",
        "        coeff_loss = F.mse_loss(coeff_pred.squeeze(), train_mb[:batch_size])\n",
        "\n",
        "        # COMBINED LOSS: Template discovery + coefficient learning\n",
        "        loss = template_loss + 0.5 * coeff_loss\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    if epoch % 30 == 0:\n",
        "        template_rmse = torch.sqrt(template_errors.mean())\n",
        "        print(f\"Epoch {epoch:3d}: Template RMSE={template_rmse:.4f}, Coeffs={coeffs[0].detach().numpy()}\")\n",
        "\n",
        "        if template_rmse < best_template_rmse:\n",
        "            best_template_rmse = template_rmse\n",
        "            best_coeffs = coeffs.detach()\n",
        "\n",
        "print(f\"\\nðŸ† GNN DISCOVERY COMPLETE!\")\n",
        "print(f\"   ðŸŽ¯ Best Template RMSE: {best_template_rmse:.4f} mag\")\n",
        "print(f\"   ðŸ“ˆ Learned coeffs: a={best_coeffs[0,0]:.3f}, b={best_coeffs[0,1]:.3f}, c={best_coeffs[0,2]:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaJfJVxGa8R6",
        "outputId": "bc695684-6348-414f-91e1-7109b4acffd5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”¬ GNN learns: Î£(SN_error_per_formula) + coefficient physics!\n",
            "Epoch   0: Template RMSE=15.5128, Coeffs=[0.00201013 0.00786885 0.990121  ]\n",
            "Epoch  30: Template RMSE=0.8724, Coeffs=[0.00242544 0.00463477 0.99293983]\n",
            "Epoch  60: Template RMSE=0.8966, Coeffs=[0.00860202 0.0033956  0.9880023 ]\n",
            "Epoch  90: Template RMSE=0.9014, Coeffs=[0.00911    0.00188931 0.9890007 ]\n",
            "Epoch 120: Template RMSE=0.7631, Coeffs=[9.4663072e-03 9.3468797e-04 9.8959899e-01]\n",
            "\n",
            "ðŸ† GNN DISCOVERY COMPLETE!\n",
            "   ðŸŽ¯ Best Template RMSE: 0.7631 mag\n",
            "   ðŸ“ˆ Learned coeffs: a=0.009, b=0.001, c=0.990\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "all_predictions = []\n",
        "\n",
        "# FIXED: Proper batch processing for ALL graphs\n",
        "with torch.no_grad():\n",
        "    for batch in train_loader:\n",
        "        preds = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
        "        all_predictions.append(preds[0]) # Extract only the template predictions (template_preds)\n",
        "\n",
        "all_preds = torch.cat(all_predictions, dim=0)[:len(train_mb), :]  # [23 SNe, 108 templates]\n",
        "\n",
        "# RANK FORMULAS BY TOTAL ERROR ACROSS ALL SUPERNOVAE (YOUR IDEA!)\n",
        "template_rmses = torch.sqrt(F.mse_loss(all_preds.T, train_mb.unsqueeze(0), reduction='none').mean(dim=1))\n",
        "\n",
        "best_idx = template_rmses.argmin().item()\n",
        "best_rmse = template_rmses[best_idx].item()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ðŸ† YOUR GNN-DISCOVERED BEST FORMULA!\")\n",
        "print(\"=\"*70)\n",
        "print(f\"   ðŸŽ¯ BEST: Template #{best_idx}\")\n",
        "print(f\"   ðŸ“ Formula: {templates[best_idx]}\")\n",
        "print(f\"   ðŸ“Š Training RMSE: {best_rmse:.4f} mag\")\n",
        "print(f\"   ðŸ“‰ vs Tripp 0.130: {'âœ… BEATS!' if best_rmse<0.13 else 'ðŸ”„ Close'}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# TOP 5\n",
        "top5_idx = template_rmses.topk(5, largest=False).indices # Use largest=False to get the smallest RMSEs\n",
        "print(\"\\nðŸ“Š TOP 5 GNN FORMULAS:\")\n",
        "for i, idx in enumerate(top5_idx):\n",
        "    print(f\"  {i+1}. {templates[idx][:45]:<45} â†’ {template_rmses[idx]:.4f} mag\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upT3xcNbcVgB",
        "outputId": "f07ba167-f60f-456d-fa83-d63ceee7ce32"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "ðŸ† YOUR GNN-DISCOVERED BEST FORMULA!\n",
            "======================================================================\n",
            "   ðŸŽ¯ BEST: Template #13\n",
            "   ðŸ“ Formula: a*M_V-EBV\n",
            "   ðŸ“Š Training RMSE: 0.0536 mag\n",
            "   ðŸ“‰ vs Tripp 0.130: âœ… BEATS!\n",
            "======================================================================\n",
            "\n",
            "ðŸ“Š TOP 5 GNN FORMULAS:\n",
            "  1. a*M_V-EBV                                     â†’ 0.0536 mag\n",
            "  2. a*Delta_m15-EBV                               â†’ 0.0549 mag\n",
            "  3. a*EBV+b*M_V+c*Delta_m15                       â†’ 0.0553 mag\n",
            "  4. a*M_V+b*Delta_m15+c*Delta_m15                 â†’ 0.0553 mag\n",
            "  5. a*log(EBV)+b*Delta_m15                        â†’ 0.0553 mag\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "all_predictions = []\n",
        "\n",
        "# FIXED: Proper batch processing for ALL graphs\n",
        "with torch.no_grad():\n",
        "    for batch in train_loader:\n",
        "        preds = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
        "        all_predictions.append(preds[0]) # Extract only the template predictions (template_preds)\n",
        "\n",
        "all_preds = torch.cat(all_predictions, dim=0)[:len(train_mb), :]  # [23 SNe, 108 templates]\n",
        "\n",
        "# RANK FORMULAS BY TOTAL ERROR ACROSS ALL SUPERNOVAE (YOUR IDEA!)\n",
        "template_rmses = torch.sqrt(F.mse_loss(all_preds.T, train_mb.unsqueeze(0), reduction='none').mean(dim=1))\n",
        "\n",
        "best_idx = template_rmses.argmin().item()\n",
        "best_rmse = template_rmses[best_idx].item()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ðŸ† YOUR GNN-DISCOVERED BEST FORMULA!\")\n",
        "print(\"=\"*70)\n",
        "print(f\"   ðŸŽ¯ BEST: Template #{best_idx}\")\n",
        "print(f\"   ðŸ“ Formula: {templates[best_idx]}\")\n",
        "print(f\"   ðŸ“Š Training RMSE: {best_rmse:.4f} mag\")\n",
        "print(f\"   ðŸ“‰ vs Tripp 0.130: {'âœ… BEATS!' if best_rmse<0.13 else 'ðŸ”„ Close'}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# TOP 5\n",
        "top5_idx = template_rmses.topk(5, largest=False).indices # Use largest=False to get the smallest RMSEs\n",
        "print(\"\\nðŸ“Š TOP 5 GNN FORMULAS:\")\n",
        "for i, idx in enumerate(top5_idx):\n",
        "    print(f\"  {i+1}. {templates[idx][:45]:<45} â†’ {template_rmses[idx]:.4f} mag\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHF_9utCbPFP",
        "outputId": "3506ea11-54d1-40f5-d16c-ed4f6d95632d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "ðŸ† YOUR GNN-DISCOVERED BEST FORMULA!\n",
            "======================================================================\n",
            "   ðŸŽ¯ BEST: Template #89\n",
            "   ðŸ“ Formula: a*Delta_m15+b*M_V\n",
            "   ðŸ“Š Training RMSE: 0.7182 mag\n",
            "   ðŸ“‰ vs Tripp 0.130: ðŸ”„ Close\n",
            "======================================================================\n",
            "\n",
            "ðŸ“Š TOP 5 GNN FORMULAS:\n",
            "  1. a*Delta_m15+b*M_V                             â†’ 0.7182 mag\n",
            "  2. a*Delta_m15**2                                â†’ 0.7184 mag\n",
            "  3. a*M_V+b*Delta_m15+c*Delta_m15                 â†’ 0.7189 mag\n",
            "  4. a*Delta_m15+b*M_V+c*EBV                       â†’ 0.7194 mag\n",
            "  5. a*Delta_m15*M_V                               â†’ 0.7197 mag\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3rd\n",
        "\n",
        "\n",
        "\n",
        "taking the wieghts ...coefficeints and calculating the coefficients for the formulas that we have given as an inpur for each formula for each supernovae dataset...and then for that it calultaes the error for each formula....\n",
        "\n",
        "\n",
        "after that ..it will look into all the formulas an its coefficients and its error across all the suprnovae, the least error formula will be treated as the best formula for us\n"
      ],
      "metadata": {
        "id": "It3vz7WRd1gs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 4F: GNN LEARNS 108 SETS OF (a_i,b_i,c_i) COEFFICIENTS!\n",
        "print(\"ðŸš€ GNN learns 108 coefficient sets â†’ ranks by SN error!\")\n",
        "\n",
        "class PerFormulaGNN(torch.nn.Module):\n",
        "    def __init__(self, input_dim=4, edge_dim=6, hidden_dim=64, n_templates=108, n_params=3):\n",
        "        super().__init__()\n",
        "        # Physics message passing (6D edges)\n",
        "        self.conv1 = TransformerConv(input_dim, hidden_dim//2, heads=2, edge_dim=edge_dim)\n",
        "        # For conv2, input is hidden_dim (64). Output is hidden_dim (64) with 1 head.\n",
        "        # So, edge_attr needs to be projected to 64. We'll do this manually.\n",
        "        self.conv2 = TransformerConv(hidden_dim, hidden_dim, heads=1) # Removed edge_dim here\n",
        "        self.proj_edge_for_conv2 = torch.nn.Linear(edge_dim, hidden_dim) # Manual projection for conv2\n",
        "        self.pool = global_add_pool\n",
        "\n",
        "        # PER-FORMULA COEFFICIENTS: [108 formulas Ã— 3 params]\n",
        "        self.formula_coeffs = torch.nn.Parameter(torch.randn(n_templates, n_params) * 0.1)\n",
        "\n",
        "        # Template structure embedding (which params each formula uses)\n",
        "        self.template_emb = torch.nn.Embedding(n_templates, hidden_dim) # Adjusted to hidden_dim output of conv2\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr, batch):\n",
        "        # 6D PHYSICS LEARNING\n",
        "        x = self.conv1(x, edge_index, edge_attr)\n",
        "        x = F.elu(x)\n",
        "\n",
        "        # Manually project edge_attr for conv2\n",
        "        projected_edge_attr = self.proj_edge_for_conv2(edge_attr) # Shape: [num_edges_in_batch, hidden_dim]\n",
        "        # Reshape to [num_messages, heads, channels_per_head] for TransformerConv's internal addition\n",
        "        projected_edge_attr_reshaped = projected_edge_attr.view(\n",
        "            -1, self.conv2.heads, self.conv2.out_channels // self.conv2.heads\n",
        "        )\n",
        "\n",
        "        x = self.conv2(x, edge_index, projected_edge_attr_reshaped) # Use the reshaped projected_edge_attr\n",
        "        x = F.elu(x)\n",
        "        graph_emb = self.pool(x, batch)  # [batch_size, hidden]\n",
        "\n",
        "        # Extract original parameters for each SN in the batch\n",
        "        # The 'x' passed to forward is already the concatenated node features from all graphs in the batch.\n",
        "        # It has shape [total_num_nodes_in_batch, input_dim=4]\n",
        "        # For each node (supernova), its features are [M_B, Delta_m15, EBV, M_V]\n",
        "        # So we need the columns 1, 2, 3 of 'x'.\n",
        "        input_params_for_coeffs = x[:, 1:4] # FIXED: use 'x' instead of 'batch.x'\n",
        "\n",
        "        # APPLY ALL 108 FORMULAS: M_B_pred[i] = params @ coeffs[i]\n",
        "        # predictions should be [total_num_nodes_in_batch, 108]\n",
        "        # `input_params_for_coeffs` is [total_num_nodes_in_batch, 3]\n",
        "        # `self.formula_coeffs` is [108, 3]\n",
        "        predictions = input_params_for_coeffs @ self.formula_coeffs.T # [total_num_nodes_in_batch, 3] @ [3, 108] -> [total_num_nodes_in_batch, 108]\n",
        "\n",
        "        return predictions, self.formula_coeffs  # Return predictions + ALL coefficients\n",
        "\n",
        "# NEW MODEL (save old one)\n",
        "original_model = model\n",
        "model = PerFormulaGNN(n_templates=len(templates))\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0s2Xcfcd3Jd",
        "outputId": "702a0265-22a1-491b-c8dc-0d6194bfa4dc"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ GNN learns 108 coefficient sets â†’ ranks by SN error!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 4G: GNN TRAINS 108 FORMULAS SIMULTANEOUSLY!\n",
        "print(\"ðŸ”¬ Training 108 formulas â†’ each with own (a_i,b_i,c_i) â†’ rank by error!\")\n",
        "\n",
        "model.train()\n",
        "best_total_rmse = float('inf')\n",
        "\n",
        "for epoch in range(100):\n",
        "    epoch_losses = []\n",
        "\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        # Pass original edge_attr to conv1. conv2 will receive projected edge_attr.\n",
        "        predictions, all_coeffs = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
        "\n",
        "        # YOUR IDEA: ERROR PER FORMULA, PER SUPERNOVA!\n",
        "        batch_size = predictions.size(0)\n",
        "\n",
        "        # Targets should be train_mb corresponding to the current batch of supernovae\n",
        "        # `batch.y` would be ideal if DataLoader mapped targets. Otherwise, slice train_mb.\n",
        "        # Assuming `batch` object passed to train_loader has `y` attribute for targets, or we slice `train_mb`.\n",
        "        # From Cell 4A, `train_loader` is `DataLoader(all_graphs, ...)`. `all_graphs` are `Data(x=x_full, ...)`.\n",
        "        # `x_full` is `[train_mb, Delta_m15, EBV, M_V]`. So `batch.x[:,0]` are the M_B targets for the batch.\n",
        "\n",
        "        targets = batch.x[:, 0] # Extract M_B targets from the first feature of each node in the batch\n",
        "        targets = targets.unsqueeze(-1).repeat(1, len(templates)) # [batch_size, 108]\n",
        "\n",
        "        # MSE PER FORMULA: [108 formulas]\n",
        "        formula_errors = F.mse_loss(predictions, targets, reduction='none').mean(dim=0)  # [108]\n",
        "\n",
        "        # TOTAL LOSS = SUM OF ALL FORMULA ERRORS (backprop to all coeffs!)\n",
        "        loss = formula_errors.mean()\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "        optimizer.step()\n",
        "        epoch_losses.append(loss.item())\n",
        "\n",
        "    if epoch % 20 == 0:\n",
        "        total_rmse = torch.sqrt(torch.tensor(formula_errors).mean()) # Calculate RMSE from current formula_errors\n",
        "        print(f\"Epoch {epoch:3d}: Avg RMSE={total_rmse:.4f} | Best formula RMSE={torch.sqrt(formula_errors.min()):.4f}\") # Added sqrt to best formula RMSE\n",
        "\n",
        "        if total_rmse < best_total_rmse:\n",
        "            best_total_rmse = total_rmse\n",
        "\n",
        "print(f\"\\nðŸ† 108-FORMULA GNN COMPLETE! Best RMSE: {best_total_rmse:.4f} mag\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6SqJo4GeNYv",
        "outputId": "2ce2a6db-fdf8-4fd5-b731-6a2cf0a4243f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”¬ Training 108 formulas â†’ each with own (a_i,b_i,c_i) â†’ rank by error!\n",
            "Epoch   0: Avg RMSE=18.0492 | Best formula RMSE=17.5590\n",
            "Epoch  20: Avg RMSE=0.3655 | Best formula RMSE=0.2129\n",
            "Epoch  40: Avg RMSE=0.0985 | Best formula RMSE=0.0779\n",
            "Epoch  60: Avg RMSE=0.0726 | Best formula RMSE=0.0644\n",
            "Epoch  80: Avg RMSE=0.0651 | Best formula RMSE=0.0592\n",
            "\n",
            "ðŸ† 108-FORMULA GNN COMPLETE! Best RMSE: 0.0651 mag\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 5F: TOP 3 FORMULAS WITH THEIR LEARNED COEFFICIENTS AND RMSE!\n",
        "print(\"ðŸ”¬ Displaying Top 3 GNN-Discovered Formulas with Coefficients and RMSE...\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ðŸ† TOP 3 GNN FORMULAS (WITH LEARNED COEFFICIENTS)! \")\n",
        "print(\"======================================================================\")\n",
        "\n",
        "# Ensure top5_idx is available from previous cell execution\n",
        "# top5_idx = template_rmses.topk(5, largest=False).indices\n",
        "\n",
        "for i, idx in enumerate(top5_idx[:3]): # Iterate through the top 3 indices\n",
        "    formula_str = templates[idx]\n",
        "    rmse_val = template_rmses[idx].item()\n",
        "    coeffs_for_formula = model.formula_coeffs[idx].detach().cpu().numpy()\n",
        "\n",
        "    coeff_delta_m15 = coeffs_for_formula[0]\n",
        "    coeff_ebv = coeffs_for_formula[1]\n",
        "    coeff_m_v = coeffs_for_formula[2]\n",
        "\n",
        "    print(f\"\\nFormula #{idx} (Rank {i+1}): {formula_str}\")\n",
        "    print(f\"  -> Training RMSE: {rmse_val:.4f} mag\")\n",
        "    print(f\"  -> Learned Coefficients (for Delta_m15, EBV, M_V respectively):\")\n",
        "    print(f\"     [Delta_m15_coeff={coeff_delta_m15:.4f}, EBV_coeff={coeff_ebv:.4f}, M_V_coeff={coeff_m_v:.4f}]\")\n",
        "    print(\"----------------------------------------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lr1CBiNpiW6O",
        "outputId": "b3d2cbcd-0202-4627-fdf0-b8826712525d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”¬ Displaying Top 3 GNN-Discovered Formulas with Coefficients and RMSE...\n",
            "\n",
            "======================================================================\n",
            "ðŸ† TOP 3 GNN FORMULAS (WITH LEARNED COEFFICIENTS)! \n",
            "======================================================================\n",
            "\n",
            "Formula #13 (Rank 1): a*M_V-EBV\n",
            "  -> Training RMSE: 0.0536 mag\n",
            "  -> Learned Coefficients (for Delta_m15, EBV, M_V respectively):\n",
            "     [Delta_m15_coeff=-0.1766, EBV_coeff=0.3304, M_V_coeff=-0.0641]\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Formula #105 (Rank 2): a*Delta_m15-EBV\n",
            "  -> Training RMSE: 0.0549 mag\n",
            "  -> Learned Coefficients (for Delta_m15, EBV, M_V respectively):\n",
            "     [Delta_m15_coeff=-0.1065, EBV_coeff=0.2145, M_V_coeff=-0.1662]\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Formula #21 (Rank 3): a*EBV+b*M_V+c*Delta_m15\n",
            "  -> Training RMSE: 0.0553 mag\n",
            "  -> Learned Coefficients (for Delta_m15, EBV, M_V respectively):\n",
            "     [Delta_m15_coeff=-0.1338, EBV_coeff=0.1221, M_V_coeff=-0.1289]\n",
            "----------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 5E: DISPLAY COEFFICIENTS FOR THE BEST GNN-DISCOVERED FORMULA!\n",
        "print(\"ðŸ”¬ Extracting coefficients for the best GNN-discovered formula...\")\n",
        "\n",
        "best_formula_coeffs = model.formula_coeffs[best_idx].detach().cpu().numpy()\n",
        "\n",
        "# The best formula is 'a*M_V-EBV'\n",
        "# This implies coefficients for Delta_m15, EBV, M_V\n",
        "# The formula itself has only M_V and EBV, so conceptually 'a' applies to M_V, 'b' to EBV.\n",
        "# The `self.formula_coeffs` is [108, 3] where the 3 columns correspond to Delta_m15, EBV, M_V\n",
        "# We need to map these learned coefficients to the variables in the *specific* best formula.\n",
        "\n",
        "# The exact mapping depends on how 'a', 'b', 'c' were implicitly assigned in the `generate_thousands_physics_templates` function\n",
        "# and how `input_params_for_coeffs` (Delta_m15, EBV, M_V) aligns with `formula_coeffs` columns.\n",
        "# Assuming the order is [Delta_m15_coeff, EBV_coeff, M_V_coeff] in `model.formula_coeffs`.\n",
        "\n",
        "# Let's extract them based on the formula: 'a*M_V-EBV'\n",
        "# So, for this formula: M_V has coefficient `a`, EBV has coefficient `-1*b` (where b is EBV_coeff)\n",
        "# and Delta_m15 has coefficient 0.\n",
        "\n",
        "# Re-interpreting `formula_coeffs` for 'a*M_V - EBV'\n",
        "# The original `predictions` calculation was `input_params_for_coeffs @ self.formula_coeffs.T`\n",
        "# where `input_params_for_coeffs` is `[Delta_m15, EBV, M_V]`.\n",
        "# So `self.formula_coeffs` columns are implicitly mapped to `Delta_m15`, `EBV`, `M_V`.\n",
        "\n",
        "# For 'a*M_V - EBV' (Template #13):\n",
        "# The coefficients learned are for Delta_m15, EBV, M_V.\n",
        "# The formula is effectively: 0 * Delta_m15 + (-1) * EBV + (1) * M_V (if EBV is directly used).\n",
        "# However, our GNN learns a distinct (a,b,c) for EACH formula. So for template 13, it learned:\n",
        "coeff_delta_m15 = best_formula_coeffs[0]\n",
        "coeff_ebv = best_formula_coeffs[1]\n",
        "coeff_m_v = best_formula_coeffs[2]\n",
        "\n",
        "print(f\"\\n\" + \"=\"*70)\n",
        "print(\"ðŸ“ˆ LEARNED COEFFICIENTS FOR THE BEST FORMULA!\")\n",
        "print(\"=\"*70)\n",
        "print(f\"   Best Formula: {templates[best_idx]}\")\n",
        "print(f\"   Coefficients (from model.formula_coeffs[{best_idx}]):\")\n",
        "print(f\"     a (for Delta_m15) = {coeff_delta_m15:.4f}\")\n",
        "print(f\"     b (for EBV)       = {coeff_ebv:.4f}\")\n",
        "print(f\"     c (for M_V)       = {coeff_m_v:.4f}\")\n",
        "\n",
        "print(\"\\nInterpretation:\")\n",
        "print(f\"   M_B = ({coeff_delta_m15:.4f} * Delta_m15) + ({coeff_ebv:.4f} * EBV) + ({coeff_m_v:.4f} * M_V)\")\n",
        "print(f\"   Since the formula is 'a*M_V-EBV', this implies a significant weight for M_V, a negative for EBV, and close to zero for Delta_m15.\")\n",
        "print(f\"   Let's see if the learned coefficients align with 'a*M_V - EBV':\")\n",
        "\n",
        "# If formula was 'a*M_V - EBV', then the learned coeffs should reflect this.\n",
        "# Assuming `a` in `a*M_V-EBV` refers to `coeff_m_v` and `-EBV` refers to `coeff_ebv` being negative.\n",
        "# The template `a*M_V-EBV` is explicitly a linear combination. Let's interpret 'a' as `coeff_m_v` and `-EBV` as a single term with `-1` times `EBV` or `coeff_ebv` being negative.\n",
        "# Given `model.formula_coeffs` learns coefficients for `[Delta_m15, EBV, M_V]` in that order:\n",
        "\n",
        "print(f\"   Based on the formula '{templates[best_idx]}', we might expect:\")\n",
        "print(f\"     Coefficient for M_V (which is 'a' in the formula) = {coeff_m_v:.4f}\")\n",
        "print(f\"     Coefficient for EBV (which is '-1' in the formula) = {coeff_ebv:.4f}\")\n",
        "print(f\"     Coefficient for Delta_m15 (which is '0' in the formula) = {coeff_delta_m15:.4f}\")\n",
        "print(\"======================================================================\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrNlAHWHiTlD",
        "outputId": "b1d8763b-153f-4da2-9a79-2f661907b1ac"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”¬ Extracting coefficients for the best GNN-discovered formula...\n",
            "\n",
            "======================================================================\n",
            "ðŸ“ˆ LEARNED COEFFICIENTS FOR THE BEST FORMULA!\n",
            "======================================================================\n",
            "   Best Formula: a*M_V-EBV\n",
            "   Coefficients (from model.formula_coeffs[13]):\n",
            "     a (for Delta_m15) = -0.1766\n",
            "     b (for EBV)       = 0.3304\n",
            "     c (for M_V)       = -0.0641\n",
            "\n",
            "Interpretation:\n",
            "   M_B = (-0.1766 * Delta_m15) + (0.3304 * EBV) + (-0.0641 * M_V)\n",
            "   Since the formula is 'a*M_V-EBV', this implies a significant weight for M_V, a negative for EBV, and close to zero for Delta_m15.\n",
            "   Let's see if the learned coefficients align with 'a*M_V - EBV':\n",
            "   Based on the formula 'a*M_V-EBV', we might expect:\n",
            "     Coefficient for M_V (which is 'a' in the formula) = -0.0641\n",
            "     Coefficient for EBV (which is '-1' in the formula) = 0.3304\n",
            "     Coefficient for Delta_m15 (which is '0' in the formula) = -0.1766\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3815509",
        "outputId": "aeb56d54-9b0e-4dc8-f499-0878dd6be024"
      },
      "source": [
        "# CELL 5G: TEST PERFORMANCE OF BEST GNN-DISCOVERED FORMULA!\n",
        "print(\"ðŸ§ª Evaluating Best GNN Formula on Test Dataset...\")\n",
        "\n",
        "# Get the best formula's index and learned coefficients\n",
        "best_idx = template_rmses.argmin().item()\n",
        "best_formula_str = templates[best_idx]\n",
        "best_formula_coeffs = model.formula_coeffs[best_idx].detach().cpu().numpy()\n",
        "\n",
        "coeff_delta_m15 = best_formula_coeffs[0]\n",
        "coeff_ebv = best_formula_coeffs[1]\n",
        "coeff_m_v = best_formula_coeffs[2]\n",
        "\n",
        "# Construct the prediction for the test set\n",
        "# test_params is [13, 3] (Delta_m15, EBV, M_V)\n",
        "# The coefficients are [coeff_delta_m15, coeff_ebv, coeff_m_v]\n",
        "\n",
        "test_predictions = (\n",
        "    test_params[:, 0] * coeff_delta_m15 +\n",
        "    test_params[:, 1] * coeff_ebv +\n",
        "    test_params[:, 2] * coeff_m_v\n",
        ")\n",
        "\n",
        "# Calculate RMSE on the test set\n",
        "test_rmse = torch.sqrt(F.mse_loss(test_predictions, test_mb)).item()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ðŸ“Š TEST SET PERFORMANCE OF BEST GNN FORMULA!\")\n",
        "print(\"======================================================================\")\n",
        "print(f\"   Best Formula: {best_formula_str}\")\n",
        "print(f\"   Learned Coefficients: \")\n",
        "print(f\"     Delta_m15_coeff = {coeff_delta_m15:.4f}\")\n",
        "print(f\"     EBV_coeff       = {coeff_ebv:.4f}\")\n",
        "print(f\"     M_V_coeff       = {coeff_m_v:.4f}\")\n",
        "print(f\"   Test RMSE: {test_rmse:.4f} mag\")\n",
        "print(f\"   vs Tripp 0.130: {'âœ… BEATS!' if test_rmse < 0.13 else 'ðŸ”„ Close' if test_rmse < 0.2 else 'âŒ Not as good'}\")\n",
        "print(\"======================================================================\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§ª Evaluating Best GNN Formula on Test Dataset...\n",
            "\n",
            "======================================================================\n",
            "ðŸ“Š TEST SET PERFORMANCE OF BEST GNN FORMULA!\n",
            "======================================================================\n",
            "   Best Formula: a*M_V-EBV\n",
            "   Learned Coefficients: \n",
            "     Delta_m15_coeff = 0.1558\n",
            "     EBV_coeff       = -0.1903\n",
            "     M_V_coeff       = 0.0551\n",
            "   Test RMSE: 17.2175 mag\n",
            "   vs Tripp 0.130: âŒ Not as good\n",
            "======================================================================\n"
          ]
        }
      ]
    }
  ]
}